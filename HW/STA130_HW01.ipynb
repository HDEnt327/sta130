{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STA130 Week 01 Homework (Prelecture)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "I decided to go with the dataset provided in the instructions notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_n</th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>gender</th>\n",
       "      <th>species</th>\n",
       "      <th>birthday</th>\n",
       "      <th>personality</th>\n",
       "      <th>song</th>\n",
       "      <th>phrase</th>\n",
       "      <th>full_id</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>admiral</td>\n",
       "      <td>Admiral</td>\n",
       "      <td>male</td>\n",
       "      <td>bird</td>\n",
       "      <td>1-27</td>\n",
       "      <td>cranky</td>\n",
       "      <td>Steep Hill</td>\n",
       "      <td>aye aye</td>\n",
       "      <td>villager-admiral</td>\n",
       "      <td>https://villagerdb.com/images/villagers/thumb/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>agent-s</td>\n",
       "      <td>Agent S</td>\n",
       "      <td>female</td>\n",
       "      <td>squirrel</td>\n",
       "      <td>7-2</td>\n",
       "      <td>peppy</td>\n",
       "      <td>DJ K.K.</td>\n",
       "      <td>sidekick</td>\n",
       "      <td>villager-agent-s</td>\n",
       "      <td>https://villagerdb.com/images/villagers/thumb/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>agnes</td>\n",
       "      <td>Agnes</td>\n",
       "      <td>female</td>\n",
       "      <td>pig</td>\n",
       "      <td>4-21</td>\n",
       "      <td>uchi</td>\n",
       "      <td>K.K. House</td>\n",
       "      <td>snuffle</td>\n",
       "      <td>villager-agnes</td>\n",
       "      <td>https://villagerdb.com/images/villagers/thumb/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>al</td>\n",
       "      <td>Al</td>\n",
       "      <td>male</td>\n",
       "      <td>gorilla</td>\n",
       "      <td>10-18</td>\n",
       "      <td>lazy</td>\n",
       "      <td>Steep Hill</td>\n",
       "      <td>Ayyeeee</td>\n",
       "      <td>villager-al</td>\n",
       "      <td>https://villagerdb.com/images/villagers/thumb/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>alfonso</td>\n",
       "      <td>Alfonso</td>\n",
       "      <td>male</td>\n",
       "      <td>alligator</td>\n",
       "      <td>6-9</td>\n",
       "      <td>lazy</td>\n",
       "      <td>Forest Life</td>\n",
       "      <td>it'sa me</td>\n",
       "      <td>villager-alfonso</td>\n",
       "      <td>https://villagerdb.com/images/villagers/thumb/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>475</td>\n",
       "      <td>winnie</td>\n",
       "      <td>Winnie</td>\n",
       "      <td>female</td>\n",
       "      <td>horse</td>\n",
       "      <td>1-31</td>\n",
       "      <td>peppy</td>\n",
       "      <td>My Place</td>\n",
       "      <td>hay-OK</td>\n",
       "      <td>villager-winnie</td>\n",
       "      <td>https://villagerdb.com/images/villagers/thumb/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>477</td>\n",
       "      <td>wolfgang</td>\n",
       "      <td>Wolfgang</td>\n",
       "      <td>male</td>\n",
       "      <td>wolf</td>\n",
       "      <td>11-25</td>\n",
       "      <td>cranky</td>\n",
       "      <td>K.K. Song</td>\n",
       "      <td>snarrrl</td>\n",
       "      <td>villager-wolfgang</td>\n",
       "      <td>https://villagerdb.com/images/villagers/thumb/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>480</td>\n",
       "      <td>yuka</td>\n",
       "      <td>Yuka</td>\n",
       "      <td>female</td>\n",
       "      <td>koala</td>\n",
       "      <td>7-20</td>\n",
       "      <td>snooty</td>\n",
       "      <td>Soulful K.K.</td>\n",
       "      <td>tsk tsk</td>\n",
       "      <td>villager-yuka</td>\n",
       "      <td>https://villagerdb.com/images/villagers/thumb/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>481</td>\n",
       "      <td>zell</td>\n",
       "      <td>Zell</td>\n",
       "      <td>male</td>\n",
       "      <td>deer</td>\n",
       "      <td>6-7</td>\n",
       "      <td>smug</td>\n",
       "      <td>K.K. D&amp;B</td>\n",
       "      <td>pronk</td>\n",
       "      <td>villager-zell</td>\n",
       "      <td>https://villagerdb.com/images/villagers/thumb/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>483</td>\n",
       "      <td>zucker</td>\n",
       "      <td>Zucker</td>\n",
       "      <td>male</td>\n",
       "      <td>octopus</td>\n",
       "      <td>3-8</td>\n",
       "      <td>lazy</td>\n",
       "      <td>Spring Blossoms</td>\n",
       "      <td>bloop</td>\n",
       "      <td>villager-zucker</td>\n",
       "      <td>https://villagerdb.com/images/villagers/thumb/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>391 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     row_n        id      name  gender    species birthday personality  \\\n",
       "0        2   admiral   Admiral    male       bird     1-27      cranky   \n",
       "1        3   agent-s   Agent S  female   squirrel      7-2       peppy   \n",
       "2        4     agnes     Agnes  female        pig     4-21        uchi   \n",
       "3        6        al        Al    male    gorilla    10-18        lazy   \n",
       "4        7   alfonso   Alfonso    male  alligator      6-9        lazy   \n",
       "..     ...       ...       ...     ...        ...      ...         ...   \n",
       "386    475    winnie    Winnie  female      horse     1-31       peppy   \n",
       "387    477  wolfgang  Wolfgang    male       wolf    11-25      cranky   \n",
       "388    480      yuka      Yuka  female      koala     7-20      snooty   \n",
       "389    481      zell      Zell    male       deer      6-7        smug   \n",
       "390    483    zucker    Zucker    male    octopus      3-8        lazy   \n",
       "\n",
       "                song    phrase            full_id  \\\n",
       "0         Steep Hill   aye aye   villager-admiral   \n",
       "1            DJ K.K.  sidekick   villager-agent-s   \n",
       "2         K.K. House   snuffle     villager-agnes   \n",
       "3         Steep Hill   Ayyeeee        villager-al   \n",
       "4        Forest Life  it'sa me   villager-alfonso   \n",
       "..               ...       ...                ...   \n",
       "386         My Place    hay-OK    villager-winnie   \n",
       "387        K.K. Song   snarrrl  villager-wolfgang   \n",
       "388     Soulful K.K.   tsk tsk      villager-yuka   \n",
       "389         K.K. D&B     pronk      villager-zell   \n",
       "390  Spring Blossoms     bloop    villager-zucker   \n",
       "\n",
       "                                                   url  \n",
       "0    https://villagerdb.com/images/villagers/thumb/...  \n",
       "1    https://villagerdb.com/images/villagers/thumb/...  \n",
       "2    https://villagerdb.com/images/villagers/thumb/...  \n",
       "3    https://villagerdb.com/images/villagers/thumb/...  \n",
       "4    https://villagerdb.com/images/villagers/thumb/...  \n",
       "..                                                 ...  \n",
       "386  https://villagerdb.com/images/villagers/thumb/...  \n",
       "387  https://villagerdb.com/images/villagers/thumb/...  \n",
       "388  https://villagerdb.com/images/villagers/thumb/...  \n",
       "389  https://villagerdb.com/images/villagers/thumb/...  \n",
       "390  https://villagerdb.com/images/villagers/thumb/...  \n",
       "\n",
       "[391 rows x 11 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "row_n           0\n",
       "id              1\n",
       "name            0\n",
       "gender          0\n",
       "species         0\n",
       "birthday        0\n",
       "personality     0\n",
       "song           11\n",
       "phrase          0\n",
       "full_id         0\n",
       "url             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above shows that columns 'id' and 'song' include missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Conversation with ChatGPT:\n",
    "\n",
    "**Me:** Hi, I currently have a dataset (https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv) and I would like to know how many columns and rows the dataset has, how can I do this in python?`\n",
    "\n",
    "**ChatGPT:**\n",
    "You can use the `pandas` library in Python to load and inspect the dataset. Here's how you can do it:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset from the URL\n",
    "url = 'https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv'\n",
    "data = pd.read_csv(url)\n",
    "\n",
    "# Get the number of rows and columns\n",
    "rows, columns = data.shape\n",
    "\n",
    "print(f'The dataset has {rows} rows and {columns} columns.')\n",
    "```\n",
    "\n",
    "This will load the CSV file from the URL and then output the number of rows and columns in the dataset.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "391"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# implementation based on ChatGPT's response\n",
    "\n",
    "rows, columns = df.shape\n",
    "rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Conversation with ChatGPT\n",
    "\n",
    "**Me:** Under the context of this dataset, can you explain the meaning or definition of \"Observations\" and \"Variables\"\n",
    "\n",
    "**ChatGPT:** In the context of datasets, including the one you're working with, the terms **\"Observations\"** and **\"Variables\"** are fundamental concepts in data analysis:\n",
    "\n",
    "### 1. **Observations**:\n",
    "   - **Definition**: An observation refers to a single row in your dataset. Each row represents one unique data point or entry.\n",
    "   - **In this dataset**: Each row represents a specific **villager** from the Animal Crossing game, with information about that villager such as their name, species, gender, birthday, and personality. \n",
    "   - **Example**: In a dataset of 300 rows, each row (or observation) corresponds to a different villager.\n",
    "\n",
    "   Think of each observation as a unique record that captures the attributes or characteristics of a single entity (in this case, a villager).\n",
    "\n",
    "### 2. **Variables**:\n",
    "   - **Definition**: A variable refers to a column in your dataset. Variables are the characteristics or properties being measured or recorded for each observation.\n",
    "   - **In this dataset**: Each column (variable) represents a different attribute of the villagers, such as their **name**, **species**, **birthday**, and **personality**.\n",
    "   - **Example**: The column \"species\" is a variable that describes the species (e.g., \"Cat,\" \"Dog\") for each villager.\n",
    "\n",
    "   Variables capture different types of information. They can be:\n",
    "   - **Numerical** (like age or height)\n",
    "   - **Categorical** (like species, gender, or personality)\n",
    "   \n",
    "In summary:\n",
    "- **Observations**: The individual data points (rows), each representing one villager.\n",
    "- **Variables**: The attributes or characteristics (columns) that describe various aspects of the villagers.\n",
    "\n",
    "For example, if your dataset has 300 rows and 10 columns, you would say the dataset contains 300 **observations** and 10 **variables**.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to ChatGPT's answer, the definition of an \"observation\" is like a row in a dataset, an unique entry, datapoint to the dataset. Under the context of the dataset I chose, each \"observation\" is an entry to the information of a villager in the game \"animal crossing\"\n",
    "\n",
    "On the other hand, the definition of a \"variable\" is like the columns in a dataset, is describes the properties that is recorded for each of the observations/rows. Under the context of the dataset, each \"variable\" refers to one characteristic/attribute of a villager, such as name, gender, species, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Conversation with ChatGPT:\n",
    "\n",
    "**Me:** How can I make a summary out the provided dataset?\n",
    "\n",
    "\n",
    "**ChatGPT:** To summarize a dataset in Python, you can use the `pandas` library, which provides various functions to give an overview of the data. Here's how you can generate a summary:\n",
    "\n",
    "1. **Basic Information**: Number of rows and columns, data types, missing values, etc.\n",
    "2. **Descriptive Statistics**: Summary of numerical and categorical columns.\n",
    "3. **Unique Values**: Number of unique values per column.\n",
    "\n",
    "Here’s how you can generate a summary:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset from the URL\n",
    "url = 'https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv'\n",
    "data = pd.read_csv(url)\n",
    "\n",
    "# Basic Information\n",
    "print(\"Basic Info:\")\n",
    "print(data.info())\n",
    "print(\"\\n\")\n",
    "\n",
    "# Descriptive Statistics for numerical and categorical columns\n",
    "print(\"Descriptive Statistics (Numerical columns):\")\n",
    "print(data.describe())  # For numerical columns\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Descriptive Statistics (Categorical columns):\")\n",
    "print(data.describe(include=['object']))  # For categorical columns\n",
    "print(\"\\n\")\n",
    "\n",
    "# Checking for missing values\n",
    "print(\"Missing Values:\")\n",
    "print(data.isnull().sum())\n",
    "print(\"\\n\")\n",
    "\n",
    "# Number of unique values per column\n",
    "print(\"Unique Values per Column:\")\n",
    "print(data.nunique())\n",
    "```\n",
    "\n",
    "### Explanation:\n",
    "- `data.info()` gives an overview of the dataset, including data types and the number of non-null entries.\n",
    "- `data.describe()` generates descriptive statistics for numerical columns (mean, std, min, max, etc.).\n",
    "- `data.describe(include=['object'])` generates descriptive statistics for categorical columns.\n",
    "- `data.isnull().sum()` shows the number of missing values in each column.\n",
    "- `data.nunique()` provides the number of unique values for each column.\n",
    "\n",
    "This will give you a comprehensive summary of the dataset.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 391 entries, 0 to 390\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   row_n        391 non-null    int64 \n",
      " 1   id           390 non-null    object\n",
      " 2   name         391 non-null    object\n",
      " 3   gender       391 non-null    object\n",
      " 4   species      391 non-null    object\n",
      " 5   birthday     391 non-null    object\n",
      " 6   personality  391 non-null    object\n",
      " 7   song         380 non-null    object\n",
      " 8   phrase       391 non-null    object\n",
      " 9   full_id      391 non-null    object\n",
      " 10  url          391 non-null    object\n",
      "dtypes: int64(1), object(10)\n",
      "memory usage: 33.7+ KB\n"
     ]
    }
   ],
   "source": [
    "# Implementation based on ChatGPT's answer\n",
    "\n",
    "# Overview of the dataset\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>391.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>239.902813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>140.702672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>117.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>240.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>363.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>483.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            row_n\n",
       "count  391.000000\n",
       "mean   239.902813\n",
       "std    140.702672\n",
       "min      2.000000\n",
       "25%    117.500000\n",
       "50%    240.000000\n",
       "75%    363.500000\n",
       "max    483.000000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Statistics of the dataset\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>gender</th>\n",
       "      <th>species</th>\n",
       "      <th>birthday</th>\n",
       "      <th>personality</th>\n",
       "      <th>song</th>\n",
       "      <th>phrase</th>\n",
       "      <th>full_id</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>390</td>\n",
       "      <td>391</td>\n",
       "      <td>391</td>\n",
       "      <td>391</td>\n",
       "      <td>391</td>\n",
       "      <td>391</td>\n",
       "      <td>380</td>\n",
       "      <td>391</td>\n",
       "      <td>391</td>\n",
       "      <td>391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>390</td>\n",
       "      <td>391</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>361</td>\n",
       "      <td>8</td>\n",
       "      <td>92</td>\n",
       "      <td>388</td>\n",
       "      <td>391</td>\n",
       "      <td>391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>admiral</td>\n",
       "      <td>Admiral</td>\n",
       "      <td>male</td>\n",
       "      <td>cat</td>\n",
       "      <td>1-27</td>\n",
       "      <td>lazy</td>\n",
       "      <td>K.K. Country</td>\n",
       "      <td>wee one</td>\n",
       "      <td>villager-admiral</td>\n",
       "      <td>https://villagerdb.com/images/villagers/thumb/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>204</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id     name gender species birthday personality          song  \\\n",
       "count       390      391    391     391      391         391           380   \n",
       "unique      390      391      2      35      361           8            92   \n",
       "top     admiral  Admiral   male     cat     1-27        lazy  K.K. Country   \n",
       "freq          1        1    204      23        2          60            10   \n",
       "\n",
       "         phrase           full_id  \\\n",
       "count       391               391   \n",
       "unique      388               391   \n",
       "top     wee one  villager-admiral   \n",
       "freq          2                 1   \n",
       "\n",
       "                                                      url  \n",
       "count                                                 391  \n",
       "unique                                                391  \n",
       "top     https://villagerdb.com/images/villagers/thumb/...  \n",
       "freq                                                    1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Statistic of the dataset (Non-numeric columns)\n",
    "df.describe(include='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "row_n          391\n",
       "id             390\n",
       "name           391\n",
       "gender           2\n",
       "species         35\n",
       "birthday       361\n",
       "personality      8\n",
       "song            92\n",
       "phrase         388\n",
       "full_id        391\n",
       "url            391\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of unique values in each column\n",
    "df.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The response given by ChatGPT does not seem to be able to give summaries about each column, such as `value_counts()`, probably because I didn't specify columns in my question. Therefore I have tried to specify ChatGPT to give *simple summaries of each column*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Conversation with ChatGPT\n",
    "\n",
    "**Me:** I would like to have more specific summaries, about each column instead\n",
    "\n",
    "**ChatGPT:** To generate more specific summaries for each column in the dataset, you can iterate through the columns and provide tailored summaries based on the type of data (numerical or categorical). Below is an approach that handles each column individually:\n",
    "\n",
    "1. **Numerical Columns**: Provide descriptive statistics such as mean, median, standard deviation, minimum, and maximum.\n",
    "2. **Categorical Columns**: Provide information such as the number of unique values, most frequent value, and frequency counts.\n",
    "\n",
    "Here’s how you can generate these summaries in Python:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset from the URL\n",
    "url = 'https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv'\n",
    "data = pd.read_csv(url)\n",
    "\n",
    "# Function to summarize each column\n",
    "def summarize_column(df, column):\n",
    "    print(f\"Summary for column: {column}\")\n",
    "    if pd.api.types.is_numeric_dtype(df[column]):\n",
    "        print(f\"Type: Numerical\")\n",
    "        print(f\"Mean: {df[column].mean()}\")\n",
    "        print(f\"Median: {df[column].median()}\")\n",
    "        print(f\"Standard Deviation: {df[column].std()}\")\n",
    "        print(f\"Min: {df[column].min()}\")\n",
    "        print(f\"Max: {df[column].max()}\")\n",
    "        print(f\"Missing Values: {df[column].isnull().sum()}\")\n",
    "    elif pd.api.types.is_object_dtype(df[column]):\n",
    "        print(f\"Type: Categorical\")\n",
    "        print(f\"Number of Unique Values: {df[column].nunique()}\")\n",
    "        print(f\"Most Frequent Value: {df[column].mode()[0]}\")\n",
    "        print(f\"Frequency of Most Frequent Value: {df[column].value_counts().max()}\")\n",
    "        print(f\"Missing Values: {df[column].isnull().sum()}\")\n",
    "    else:\n",
    "        print(f\"Type: Other (possibly datetime or boolean)\")\n",
    "        print(f\"Missing Values: {df[column].isnull().sum()}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "# Iterate through each column and summarize it\n",
    "for col in data.columns:\n",
    "    summarize_column(data, col)\n",
    "```\n",
    "\n",
    "### Explanation:\n",
    "- **Numerical columns**: \n",
    "    - The script calculates the mean, median, standard deviation, minimum, and maximum values.\n",
    "- **Categorical columns**:\n",
    "    - It shows the number of unique values, the most frequent value (mode), and the frequency of the most frequent value.\n",
    "- **Other data types**: If a column isn't numerical or categorical (e.g., datetime or boolean), it’s categorized under \"Other\".\n",
    "- It also reports any missing values for each column.\n",
    "\n",
    "Running this code will give you detailed summaries for each column in your dataset.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Oops**, I messed up, the response was way too specific because I mentioned \"specific summaries\", I'm going to try to let it give more simple summaries instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Conversation with ChatGPT\n",
    "\n",
    "**Me:** Sorry, I meant to have simple summaries for each column\n",
    "\n",
    "**ChatGPT:** Ah, I see! You'd like simple summaries for each column. Here's a more concise version that provides a basic overview for each column:\n",
    "\n",
    "For **numerical columns**, it includes:\n",
    "- Count of non-missing values\n",
    "- Mean\n",
    "- Standard deviation\n",
    "- Minimum and maximum values\n",
    "\n",
    "For **categorical columns**, it includes:\n",
    "- Count of non-missing values\n",
    "- Number of unique values\n",
    "- Most frequent value (mode)\n",
    "\n",
    "Here's the code to achieve this:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset from the URL\n",
    "url = 'https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv'\n",
    "data = pd.read_csv(url)\n",
    "\n",
    "# Function to create a simple summary for each column\n",
    "def simple_column_summary(df, column):\n",
    "    print(f\"Summary for column: {column}\")\n",
    "    \n",
    "    # If the column is numerical\n",
    "    if pd.api.types.is_numeric_dtype(df[column]):\n",
    "        print(f\"Type: Numerical\")\n",
    "        print(f\"Count: {df[column].count()}\")\n",
    "        print(f\"Mean: {df[column].mean()}\")\n",
    "        print(f\"Standard Deviation: {df[column].std()}\")\n",
    "        print(f\"Min: {df[column].min()}\")\n",
    "        print(f\"Max: {df[column].max()}\")\n",
    "        \n",
    "    # If the column is categorical\n",
    "    elif pd.api.types.is_object_dtype(df[column]):\n",
    "        print(f\"Type: Categorical\")\n",
    "        print(f\"Count: {df[column].count()}\")\n",
    "        print(f\"Number of Unique Values: {df[column].nunique()}\")\n",
    "        print(f\"Most Frequent Value: {df[column].mode()[0]}\")\n",
    "        \n",
    "    print(\"\\n\")\n",
    "\n",
    "# Iterate through each column and generate a simple summary\n",
    "for col in data.columns:\n",
    "    simple_column_summary(data, col)\n",
    "```\n",
    "\n",
    "### Output Example:\n",
    "For a numerical column:\n",
    "```\n",
    "Summary for column: age\n",
    "Type: Numerical\n",
    "Count: 200\n",
    "Mean: 35.6\n",
    "Standard Deviation: 12.8\n",
    "Min: 18\n",
    "Max: 65\n",
    "```\n",
    "\n",
    "For a categorical column:\n",
    "```\n",
    "Summary for column: gender\n",
    "Type: Categorical\n",
    "Count: 200\n",
    "Number of Unique Values: 3\n",
    "Most Frequent Value: Female\n",
    "```\n",
    "\n",
    "### Explanation:\n",
    "- **Numerical columns**: Provides a quick overview with count, mean, standard deviation, min, and max.\n",
    "- **Categorical columns**: Lists the count of non-missing values, unique values, and the most frequent value.\n",
    "\n",
    "This gives you a simple but clear overview of each column in your dataset.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay... That didn't work, I'll just move on now..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The animal crossing villagers dataset earlier didn't include missing numeric values, so I had to switch to the titanic dataset instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alive</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>S</td>\n",
       "      <td>Second</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>B</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>Q</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Queenstown</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     survived  pclass     sex   age  sibsp  parch     fare embarked   class  \\\n",
       "0           0       3    male  22.0      1      0   7.2500        S   Third   \n",
       "1           1       1  female  38.0      1      0  71.2833        C   First   \n",
       "2           1       3  female  26.0      0      0   7.9250        S   Third   \n",
       "3           1       1  female  35.0      1      0  53.1000        S   First   \n",
       "4           0       3    male  35.0      0      0   8.0500        S   Third   \n",
       "..        ...     ...     ...   ...    ...    ...      ...      ...     ...   \n",
       "886         0       2    male  27.0      0      0  13.0000        S  Second   \n",
       "887         1       1  female  19.0      0      0  30.0000        S   First   \n",
       "888         0       3  female   NaN      1      2  23.4500        S   Third   \n",
       "889         1       1    male  26.0      0      0  30.0000        C   First   \n",
       "890         0       3    male  32.0      0      0   7.7500        Q   Third   \n",
       "\n",
       "       who  adult_male deck  embark_town alive  alone  \n",
       "0      man        True  NaN  Southampton    no  False  \n",
       "1    woman       False    C    Cherbourg   yes  False  \n",
       "2    woman       False  NaN  Southampton   yes   True  \n",
       "3    woman       False    C  Southampton   yes  False  \n",
       "4      man        True  NaN  Southampton    no   True  \n",
       "..     ...         ...  ...          ...   ...    ...  \n",
       "886    man        True  NaN  Southampton    no   True  \n",
       "887  woman       False    B  Southampton   yes   True  \n",
       "888  woman       False  NaN  Southampton    no  False  \n",
       "889    man        True    C    Cherbourg   yes   True  \n",
       "890    man        True  NaN   Queenstown    no   True  \n",
       "\n",
       "[891 rows x 15 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_titanic = pd.read_csv('https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv')\n",
    "df_titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "891"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Size of the dataset using df.shape\n",
    "\n",
    "rows_titanic, columns_titanic = df_titanic.shape\n",
    "rows_titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         survived      pclass         age       sibsp       parch        fare\n",
       "count  891.000000  891.000000  714.000000  891.000000  891.000000  891.000000\n",
       "mean     0.383838    2.308642   29.699118    0.523008    0.381594   32.204208\n",
       "std      0.486592    0.836071   14.526497    1.102743    0.806057   49.693429\n",
       "min      0.000000    1.000000    0.420000    0.000000    0.000000    0.000000\n",
       "25%      0.000000    2.000000   20.125000    0.000000    0.000000    7.910400\n",
       "50%      0.000000    3.000000   28.000000    0.000000    0.000000   14.454200\n",
       "75%      1.000000    3.000000   38.000000    1.000000    0.000000   31.000000\n",
       "max      1.000000    3.000000   80.000000    8.000000    6.000000  512.329200"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Size of the dataset using df.desribe()\n",
    "\n",
    "df_titanic.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I see, when I do df_titanic.shape, it tells me that the dataset has 891 rows and 15 columns, however when I do df_titanic.describe(), it is only showing 6 columns and some columns only show 714 rows. I'm guessing this is because .shape and .describe() measure the size of the dataset in different ways, ChatGPT probably knows\n",
    "\n",
    "---\n",
    "\n",
    "### Conversation with ChatGPT:\n",
    "\n",
    "**Me:** Now let's switch to a different dataset (https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv), can you explain the discrepancies between the size of the dataset reported by df.shape and df.describe()?\n",
    "\n",
    "**ChatGPT:** The discrepancies between the size of the dataset reported by `df.shape` and `df.describe()` in a dataset like the Titanic dataset can arise due to differences in what these functions report.\n",
    "\n",
    "Let’s break this down:\n",
    "\n",
    "### 1. **`df.shape`**:\n",
    "   - **What it does**: This function returns the dimensions of the entire dataset, regardless of whether the columns contain numerical, categorical, or missing values.\n",
    "   - **Output**: `(rows, columns)`, where:\n",
    "     - `rows` is the total number of observations (records).\n",
    "     - `columns` is the total number of variables (attributes).\n",
    "   - **Example**: If `df.shape` outputs `(891, 15)`, this means there are 891 rows (observations) and 15 columns (variables).\n",
    "\n",
    "### 2. **`df.describe()`**:\n",
    "   - **What it does**: This function provides descriptive statistics (such as mean, standard deviation, min, max, etc.) **only for numerical columns** by default. It only summarizes columns that are either integers or floats.\n",
    "   - **Output**: Summary statistics for the numerical columns in the dataset.\n",
    "     - **Count**: The number of non-missing values for each numerical column.\n",
    "     - **Mean**, **Standard Deviation**, **Min**, **Max**, etc. for each numerical column.\n",
    "   \n",
    "   **Note**: If you want `df.describe()` to include both **numerical and categorical** columns, you can use:\n",
    "   ```python\n",
    "   df.describe(include='all')\n",
    "   ```\n",
    "\n",
    "### Why is there a discrepancy?\n",
    "\n",
    "1. **Different Columns Considered**:\n",
    "   - `df.shape` considers all columns (numerical, categorical, etc.), while `df.describe()` (by default) only includes **numerical** columns. This can result in fewer columns being displayed by `df.describe()` compared to `df.shape`.\n",
    "\n",
    "2. **Missing Data**:\n",
    "   - `df.describe()` reports statistics based only on **non-missing values**. If a column has missing values, the `count` reported by `df.describe()` for that column will be smaller than the total number of rows reported by `df.shape`.\n",
    "   - For example, if `df.shape` says there are 891 rows but a column has missing values, `df.describe()` might show a count less than 891 for that specific column.\n",
    "\n",
    "### Example for the Titanic dataset:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset\n",
    "url = 'https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv'\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Shape of the dataset\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "\n",
    "# Descriptive statistics\n",
    "print(df.describe())\n",
    "\n",
    "# Descriptive statistics for all columns, including categorical ones\n",
    "print(df.describe(include='all'))\n",
    "```\n",
    "\n",
    "#### Sample Output:\n",
    "- **`df.shape`** might return `(891, 15)` → 891 rows and 15 columns.\n",
    "- **`df.describe()`** might only show summaries for **numerical columns** like `age`, `fare`, `sibsp` (siblings/spouses aboard), and `parch` (parents/children aboard), but **ignore categorical columns** like `sex`, `embarked`, and `class`.\n",
    "\n",
    "For example, the \"age\" column might have fewer than 891 values in `df.describe()` because some entries are missing, while `df.shape` will still report 891 rows.\n",
    "\n",
    "### In summary:\n",
    "- **`df.shape`** reports the full size of the dataset (rows and columns, including all data types and missing values).\n",
    "- **`df.describe()`** only summarizes numerical columns by default, and reports only non-missing values for those columns, leading to discrepancies in counts and the number of columns summarized.\n",
    "\n",
    "---\n",
    "\n",
    "I see! First of all, .shape directly gives me the full dimensions of the entire dataset, while .describe() gives summaries for columns individually. Since some of the columns include missing values, some of the columns would report count values that are less than 891. As seen in the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "survived         0\n",
       "pclass           0\n",
       "sex              0\n",
       "age            177\n",
       "sibsp            0\n",
       "parch            0\n",
       "fare             0\n",
       "embarked         2\n",
       "class            0\n",
       "who              0\n",
       "adult_male       0\n",
       "deck           688\n",
       "embark_town      2\n",
       "alive            0\n",
       "alone            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_titanic.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are missing values for age, embarked, embark_town, and deck, .describe() would then report smaller row coutns for these columns.\n",
    "\n",
    "This brings up the next reason why .shape and .describe() give different values, since we actually don't see the columns deck, embarked, and embarktown in what .describe() returned above, means that .describe() isn't analysing some of the columns. According to ChatGPT's response, this is due to the fact that .describe() only reports numerical values on default, therefore all of the non-numeric columns in the dataset are not reported by .describe().\n",
    "\n",
    "This actually can be negated by another answer by ChatGPT above, by passing arguments into the .describe() method, we can do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891</td>\n",
       "      <td>889</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>203</td>\n",
       "      <td>889</td>\n",
       "      <td>891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>577</td>\n",
       "      <td>644</td>\n",
       "      <td>491</td>\n",
       "      <td>537</td>\n",
       "      <td>59</td>\n",
       "      <td>644</td>\n",
       "      <td>549</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         sex embarked  class  who deck  embark_town alive\n",
       "count    891      889    891  891  203          889   891\n",
       "unique     2        3      3    3    7            3     2\n",
       "top     male        S  Third  man    C  Southampton    no\n",
       "freq     577      644    491  537   59          644   549"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Statistic of the dataset (Non-numeric columns)\n",
    "df_titanic.describe(include='object')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, .describe() is showing the same number of columns as .shape would give."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "\n",
    "---\n",
    "\n",
    "### Conversation with ChatGPT\n",
    "\n",
    "**Me:** With that said, can you explain the different between attributes and methods, such as df.shape, which does not have a parentheses at the end, and df.describe(), which does have parentheses at the end\n",
    "\n",
    "**ChatGPT:** In Python, especially when working with libraries like `pandas`, it’s essential to understand the difference between **attributes** and **methods**. This distinction explains why some operations (like `df.shape`) do not require parentheses, while others (like `df.describe()`) do.\n",
    "\n",
    "### 1. **Attributes**:\n",
    "   - **Definition**: An attribute is a property or characteristic of an object that stores a value. It's like a variable tied to an object. Attributes do not require parentheses because they represent data, not actions.\n",
    "   - **Example**: `df.shape`\n",
    "     - **What it does**: `df.shape` is an attribute of a pandas DataFrame that stores the dimensions (number of rows and columns) of the dataset.\n",
    "     - **Why no parentheses**: Since `shape` is an attribute, it simply holds information and does not perform any computation. When you call `df.shape`, it retrieves and returns the stored data directly.\n",
    "\n",
    "   - **Other Examples**:\n",
    "     - `df.columns`: Returns the names of the columns.\n",
    "     - `df.index`: Returns the index (or row labels) of the DataFrame.\n",
    "\n",
    "   Attributes are usually \"static\" in the sense that they describe the object and don't perform any dynamic calculations when accessed.\n",
    "\n",
    "### 2. **Methods**:\n",
    "   - **Definition**: A method is a function that belongs to an object. Methods perform some operation or computation on the object when called. You need parentheses to invoke (or call) a method, just like when calling a regular function.\n",
    "   - **Example**: `df.describe()`\n",
    "     - **What it does**: `df.describe()` is a method that performs a calculation on the DataFrame and returns a summary of descriptive statistics.\n",
    "     - **Why parentheses**: The parentheses are used to execute the method, i.e., to tell Python, \"perform this action.\" Methods often take arguments (which are passed inside the parentheses), although some methods, like `df.describe()`, can be called without arguments.\n",
    "\n",
    "   - **Other Examples**:\n",
    "     - `df.head()`: Displays the first few rows of the DataFrame.\n",
    "     - `df.sum()`: Calculates the sum of values for each column.\n",
    "     - `df.isnull()`: Returns a DataFrame of the same shape, indicating which cells are missing values.\n",
    "\n",
    "   Methods are \"dynamic\" because they perform actions or computations when you invoke them.\n",
    "\n",
    "### Key Differences:\n",
    "| Aspect          | Attributes              | Methods                    |\n",
    "|-----------------|-------------------------|----------------------------|\n",
    "| **Definition**  | Stores data or properties | Performs an action or operation |\n",
    "| **Parentheses** | No parentheses required | Requires parentheses to invoke |\n",
    "| **Example**     | `df.shape` (returns dimensions) | `df.describe()` (computes statistics) |\n",
    "| **Behavior**    | Retrieves a stored value | Executes a function or operation |\n",
    "\n",
    "### Summary:\n",
    "- **Attributes** represent **data** tied to an object (e.g., `df.shape`), so they do not need parentheses.\n",
    "- **Methods** are **functions** that belong to an object (e.g., `df.describe()`), and they require parentheses because they perform some operation on the object.\n",
    "\n",
    "When you see something without parentheses (like `df.shape`), you're accessing a property or value of the object. When you see parentheses (like `df.describe()`), you're instructing Python to run a function associated with that object.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An **Attribute** is a property or characteristic that an object has, they can be directly access without having to add parenthesis at the end.\n",
    "\n",
    "On the other hand, A **Method** is an action that belongs to an object, and is acted on the object, the perform some operation. A method requires parenthesis to be added at the end to signify that it is a method, and not an attribute, and to include arguments that are passed into the method, which could change how the method acts.\n",
    "\n",
    "An **Attribute** does not need parenthesis, because it is data being directly accessed, not requiring arguments to be passed in, and not actions on the objects are involved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Question 6 (Starting Postlecture)\n",
    "\n",
    "The df.describe() method gives some statistics about columns that are analyzes, I have asked ChatGPT to give me a explanation of each of the key statistics it provides.\n",
    "\n",
    "---\n",
    "\n",
    "### Conversation with ChatGPT:\n",
    "\n",
    "**Me:** So since df.describe() gives summaries for numerical columns, can you give an explanation and definition for each of the statistics it analyses? Such as \"count\", \"mean\", \"std\", etc.\n",
    "\n",
    "**ChatGPT:** Certainly! When you call `df.describe()` on a dataset with numerical columns, it provides a summary of key statistics for each column. Here's an explanation of each of these statistics:\n",
    "\n",
    "### 1. **Count**:\n",
    "   - **Definition**: The number of **non-null** (non-missing) values in the column.\n",
    "   - **Explanation**: It tells you how many valid (non-`NaN`) entries are present in the column.\n",
    "   - **Example**: If a column has 891 total entries but 177 are missing, the count will be 714.\n",
    "\n",
    "### 2. **Mean**:\n",
    "   - **Definition**: The **average** value of the column.\n",
    "   - **Formula**: Sum of all non-null values divided by the count of non-null values.\n",
    "   - **Explanation**: It gives a central tendency of the data by averaging all valid values in the column.\n",
    "   - **Example**: In the Titanic dataset, if the `age` column has a mean of `29.7`, it means the average age of the passengers (for whom the age is known) is 29.7 years.\n",
    "\n",
    "### 3. **Standard Deviation (std)**:\n",
    "   - **Definition**: A measure of the **spread** or **dispersion** of values in the column.\n",
    "   - **Formula**: It's the square root of the variance, which is the average of the squared differences from the mean.\n",
    "   - **Explanation**: The larger the standard deviation, the more spread out the values are from the mean. A small standard deviation means the values are clustered closer to the mean.\n",
    "   - **Example**: If `std` for the `fare` column is high, it means passengers paid widely varying ticket prices.\n",
    "\n",
    "### 4. **Minimum (min)**:\n",
    "   - **Definition**: The **smallest** non-null value in the column.\n",
    "   - **Explanation**: It tells you the lowest value in the dataset for that column.\n",
    "   - **Example**: In the `age` column, if `min = 0.42`, it means the youngest passenger was 0.42 years old (about 5 months).\n",
    "\n",
    "### 5. **25th Percentile (25%) / First Quartile (Q1)**:\n",
    "   - **Definition**: The value below which **25%** of the data falls.\n",
    "   - **Explanation**: It gives an idea of the lower quarter of the data distribution. This value is known as the **first quartile** (Q1).\n",
    "   - **Example**: If the 25th percentile for `fare` is `7.91`, it means 25% of passengers paid a fare of less than or equal to 7.91.\n",
    "\n",
    "### 6. **50th Percentile (50%) / Median**:\n",
    "   - **Definition**: The value below which **50%** of the data falls (the **middle value** when the data is ordered).\n",
    "   - **Explanation**: This is the **median**, which is less affected by outliers than the mean. Half of the values are below this number, and half are above it.\n",
    "   - **Example**: If the median `age` is `28`, half of the passengers were younger than 28 years old, and the other half were older.\n",
    "\n",
    "### 7. **75th Percentile (75%) / Third Quartile (Q3)**:\n",
    "   - **Definition**: The value below which **75%** of the data falls.\n",
    "   - **Explanation**: It gives an idea of the upper quarter of the data distribution. This value is known as the **third quartile** (Q3).\n",
    "   - **Example**: If the 75th percentile for `fare` is `31.0`, it means 75% of passengers paid a fare of less than or equal to 31.0.\n",
    "\n",
    "### 8. **Maximum (max)**:\n",
    "   - **Definition**: The **largest** non-null value in the column.\n",
    "   - **Explanation**: It tells you the highest value in the dataset for that column.\n",
    "   - **Example**: In the `fare` column, if `max = 512.3292`, it means the highest ticket fare paid by any passenger was 512.33 (in whatever currency was used).\n",
    "\n",
    "### Example from the Titanic Dataset:\n",
    "\n",
    "Suppose you run `df.describe()` on the Titanic dataset, and it gives the following summary for the `age` column:\n",
    "\n",
    "|       | age   |\n",
    "|-------|-------|\n",
    "| count | 714   |\n",
    "| mean  | 29.70 |\n",
    "| std   | 14.52 |\n",
    "| min   | 0.42  |\n",
    "| 25%   | 20.12 |\n",
    "| 50%   | 28.00 |\n",
    "| 75%   | 38.00 |\n",
    "| max   | 80.00 |\n",
    "\n",
    "- **count**: 714 passengers have a known age.\n",
    "- **mean**: The average age of passengers is 29.7 years.\n",
    "- **std**: The standard deviation of age is 14.52 years, meaning there's a considerable spread around the average.\n",
    "- **min**: The youngest passenger is 0.42 years old.\n",
    "- **25%**: The first quartile is 20.12, meaning 25% of the passengers are younger than 20.12 years.\n",
    "- **50%**: The median age is 28 years.\n",
    "- **75%**: The third quartile is 38 years, so 75% of the passengers are younger than 38.\n",
    "- **max**: The oldest passenger is 80 years old.\n",
    "\n",
    "### Summary:\n",
    "- **Count**: Number of non-missing values.\n",
    "- **Mean**: Average value.\n",
    "- **Std**: Spread of values (standard deviation).\n",
    "- **Min**: Smallest value.\n",
    "- **25%**: Value below which 25% of data falls (first quartile).\n",
    "- **50%**: Median (middle value).\n",
    "- **75%**: Value below which 75% of data falls (third quartile).\n",
    "- **Max**: Largest value.\n",
    "\n",
    "These statistics give a quick snapshot of the distribution of data in each numerical column, allowing you to understand its central tendency, variability, and range.\n",
    "\n",
    "---\n",
    "\n",
    "Based on ChatGPT's answer, I now have a definition for each of the key statistics df.describe() gives.\n",
    "\n",
    "**Count** gives the amount of non-null values in the column analyzed.\n",
    "\n",
    "**Mean** gives the average value of the columns. It adds up all of the numeric non-null values in the column, and divides the sum by the amount of non-null values. It gives a centural tendency of the values of the column.\n",
    "\n",
    "**Std**, which is short for standard deviation, is a measurement that describe how spread out or dispersed the values in the column are. \"std\" is measured by taking the square root of the variance, which is the average of the squared differences between each of the values and the mean. \"std\" can be interpreted by looking at how large the value is, the larger \"std\" is, the more spread out the values are, and vice versa.\n",
    "\n",
    "**Min** gives the smallest value in the column\n",
    "\n",
    "**25%**, which is short for the 25th percentile, or the first quartile gives the value in the column which is higher than 25% of the total number of values. The first quartile values gives an idea of the values at the lower part of the column.\n",
    "\n",
    "**50%**, which is short for the 50th percentile, which is also the median, is the middle value of the column, the value which is higher than 50% of the total number of values in the column.\n",
    "\n",
    "**75%**, which is short for the 75th percentile, or the third quartile, gives "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 7\n",
    "\n",
    "There is a very important distinction between these two methods, df.dropna() automatically looks for null values in the dataset and removes the rows that contain missing values. While by default it removes rows, it can also be configured to remove columns by passing in an argument \"axis=1\". While the \"del df['col']\" operation removes a set column, which makes it useful when it is known which columns are not useful, or won't be used during the analysis that will be performed on the dataset.\n",
    "\n",
    "### 7.1\n",
    "\n",
    "With the differences between the two operations or methods, a use case in which using df.dropna() is more preferred when either a simple cleanup of the dataset is desired or there are not many missing values distributed between multiple rows, which could cause df.dropna() to remove a very large portion of the dataset. In that case --\n",
    "\n",
    "### 7.2\n",
    "\n",
    "-- (continued) the operation \"del df['col']\" would be more preferred, by locating the column where there are large amounts of missing values, and therefore that column could simply be removed as a whole. Alternatively, this operation could also be used to remove columns and variables that are no longer needed for the analysis.\n",
    "\n",
    "### 7.3\n",
    "\n",
    "And thus, combining what was explained earlier, if we were to use both df.dropna() and del df['col'] together, the latter should be preferred to be used first to remove columns with high amounts of missing values, so that when df.dropna() is executed, large portions of rows won't be removed due to that columns having lots of missing values.\n",
    "\n",
    "### 7.4\n",
    "\n",
    "Using the df_titanic dataset estalished earlier, we can justify the reasoning of the usage of the two operations:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "survived         0\n",
       "pclass           0\n",
       "sex              0\n",
       "age            177\n",
       "sibsp            0\n",
       "parch            0\n",
       "fare             0\n",
       "embarked         2\n",
       "class            0\n",
       "who              0\n",
       "adult_male       0\n",
       "deck           688\n",
       "embark_town      2\n",
       "alive            0\n",
       "alone            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_titanic.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen above, the deck column has 688 missing values, if df.dropna() was executed without removing this column, a whole 688 total rows would be removed, which is certainly not desireable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(182, 15)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_removed_df_titanic = df_titanic.dropna()\n",
    "bad_removed_df_titanic.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen, the original 891 rows has been cut down to 182, due to not firstly removing the deck column.\n",
    "\n",
    "So, we should first remove the deck column, before executing df.dropna():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(712, 14)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_removed_df_titanic = df_titanic  # Making a copy of the dataset\n",
    "del good_removed_df_titanic['deck']   # Removing the 'deck' column\n",
    "good_removed_df_titanic = good_removed_df_titanic.dropna()\n",
    "good_removed_df_titanic.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, instead of cutting down the dataset to only 182 rows, we have 712 left, which is still a big different with the original 891, and this is due to the column age also having a large number of missing values. However, age could be essential to the analysis of the dataset, thus might not be removed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qustion 8\n",
    "\n",
    "### 8.1\n",
    "\n",
    "---\n",
    "\n",
    "### Conversation with ChatGPT:\n",
    "\n",
    "**Me:** Can you explain what df.groupby(\"col1\")[\"col2\"].describe() would do\n",
    "\n",
    "**ChatGPT:** Certainly! The operation `df.groupby(\"col1\")[\"col2\"].describe()` in pandas involves **grouping**, **selecting**, and **summarizing** data. Here's a breakdown of what each part of this command does:\n",
    "\n",
    "### 1. **`df.groupby(\"col1\")`**:\n",
    "   - **What it does**: This groups the DataFrame `df` by the unique values in **\"col1\"**.\n",
    "   - **Explanation**: Grouping means splitting the DataFrame into **subsets** based on the unique values of a specified column (in this case, \"col1\"). Each unique value in \"col1\" defines a separate group.\n",
    "   - **Example**: If \"col1\" represents \"gender\" (with values \"M\" and \"F\"), this will split the DataFrame into two groups: one for \"M\" (males) and one for \"F\" (females).\n",
    "\n",
    "### 2. **`[\"col2\"]`**:\n",
    "   - **What it does**: This selects only the column **\"col2\"** from the grouped DataFrame.\n",
    "   - **Explanation**: After the DataFrame is grouped by \"col1\", this step focuses on analyzing only \"col2\" within each group.\n",
    "   - **Example**: If \"col2\" represents \"age\", this selects the \"age\" column from each group that was created by grouping based on \"gender\".\n",
    "\n",
    "### 3. **`.describe()`**:\n",
    "   - **What it does**: This computes summary statistics for **\"col2\"** within each group.\n",
    "   - **Explanation**: The `.describe()` method calculates a range of descriptive statistics (like `count`, `mean`, `std`, `min`, `25%`, `50%`, `75%`, and `max`) for \"col2\", but separately for each group defined by \"col1\".\n",
    "   - **Example**: If \"col2\" is \"age\" and \"col1\" is \"gender\", `describe()` will compute summary statistics for the \"age\" column **separately** for males and females. You will get two sets of descriptive statistics: one for males and one for females.\n",
    "\n",
    "### Putting It All Together:\n",
    "The command `df.groupby(\"col1\")[\"col2\"].describe()`:\n",
    "1. **Groups** the DataFrame by the unique values in **\"col1\"** (e.g., groups by gender).\n",
    "2. **Selects** the column **\"col2\"** from within each group (e.g., selects the \"age\" column).\n",
    "3. **Calculates** summary statistics (like `mean`, `std`, `min`, etc.) for **\"col2\"** within each group.\n",
    "\n",
    "### Example:\n",
    "Consider this small example DataFrame:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "data = {'gender': ['M', 'F', 'M', 'F', 'M'],\n",
    "        'age': [25, 30, 22, 29, 24]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "```\n",
    "\n",
    "If we run `df.groupby(\"gender\")[\"age\"].describe()`, the result might look like:\n",
    "\n",
    "| gender | count | mean | std  | min | 25%  | 50%  | 75%  | max |\n",
    "|--------|-------|------|------|-----|------|------|------|-----|\n",
    "| F      | 2     | 29.5 | 0.71 | 29  | 29.25| 29.5 | 29.75| 30  |\n",
    "| M      | 3     | 23.67| 1.53 | 22  | 23.0 | 24   | 24.5 | 25  |\n",
    "\n",
    "### Interpretation:\n",
    "- **\"F\" group (females)**: The summary statistics for \"age\" include a count of 2 (there are 2 females), a mean age of 29.5, a standard deviation of 0.71, and so on.\n",
    "- **\"M\" group (males)**: The summary statistics for \"age\" show a count of 3, a mean age of 23.67, and a higher standard deviation of 1.53, indicating that the ages of males are more spread out than those of females.\n",
    "\n",
    "### Summary:\n",
    "- **`df.groupby(\"col1\")`**: Groups the data by unique values in \"col1\".\n",
    "- **`[\"col2\"]`**: Selects the column \"col2\" from each group.\n",
    "- **`.describe()`**: Calculates summary statistics (count, mean, std, min, max, etc.) for \"col2\" in each group separately.\n",
    "\n",
    "This is a powerful way to explore the distribution of a column's values (e.g., \"age\") across different categories (e.g., \"gender\").\n",
    "\n",
    "---\n",
    "\n",
    "According to the response from ChatGPT, the operation `df.groupby(\"col1\")[\"col2\"].describe()` consists of multiple different parts. first, `df.groupby(\"col1\")` groups together unique values in the column \"col1\", making them the columns of a new dataframe. Then, `[col2]` selects the \"col2\" from the newly created dataframe, and finally `describe()` reports statistics about \"col2\".\n",
    "\n",
    "According to ChatGPT, this can be useful when performing analysis based of different categories such as gender, and we can try to apply this to the titanic dataset, since it also involves gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alive</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>S</td>\n",
       "      <td>Second</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>Q</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>Queenstown</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     survived  pclass     sex   age  sibsp  parch     fare embarked   class  \\\n",
       "0           0       3    male  22.0      1      0   7.2500        S   Third   \n",
       "1           1       1  female  38.0      1      0  71.2833        C   First   \n",
       "2           1       3  female  26.0      0      0   7.9250        S   Third   \n",
       "3           1       1  female  35.0      1      0  53.1000        S   First   \n",
       "4           0       3    male  35.0      0      0   8.0500        S   Third   \n",
       "..        ...     ...     ...   ...    ...    ...      ...      ...     ...   \n",
       "886         0       2    male  27.0      0      0  13.0000        S  Second   \n",
       "887         1       1  female  19.0      0      0  30.0000        S   First   \n",
       "888         0       3  female   NaN      1      2  23.4500        S   Third   \n",
       "889         1       1    male  26.0      0      0  30.0000        C   First   \n",
       "890         0       3    male  32.0      0      0   7.7500        Q   Third   \n",
       "\n",
       "       who  adult_male  embark_town alive  alone  \n",
       "0      man        True  Southampton    no  False  \n",
       "1    woman       False    Cherbourg   yes  False  \n",
       "2    woman       False  Southampton   yes   True  \n",
       "3    woman       False  Southampton   yes  False  \n",
       "4      man        True  Southampton    no   True  \n",
       "..     ...         ...          ...   ...    ...  \n",
       "886    man        True  Southampton    no   True  \n",
       "887  woman       False  Southampton   yes   True  \n",
       "888  woman       False  Southampton    no  False  \n",
       "889    man        True    Cherbourg   yes   True  \n",
       "890    man        True   Queenstown    no   True  \n",
       "\n",
       "[891 rows x 14 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>female</th>\n",
       "      <td>314</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td>577</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "      <td>468</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       count unique  top freq\n",
       "sex                          \n",
       "female   314      2  yes  233\n",
       "male     577      2   no  468"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_titanic.groupby('sex')['alive'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As such, by grouping the 'sex' columns based on the two unique values 'female' and 'male', and looking at the total number of 'alive' in the column, then running df.describe(), we can actually see that the titanic actually has more males survive compared to females!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2\n",
    "\n",
    "The count given by df.describe() and df.groupby().describe are fundamentally different because they are serve very different purposes and therefore perform the counting operations differently.\n",
    "\n",
    "df.describe() gives statistics calculations for the entire dataframe, column by column, and the count given by the method call reflects the total number of null values in each columns across the entire dataframe.\n",
    "\n",
    "On the other hand, df.groupby().describe() first groups the columns in the dataframe based on unique values in the column, and then describe() computes the statistics for each group separately. In this case, the count for each **group** reflects the total number of null values in **each group**, which could differ from the overall total count if the two groups have imbalanced amounts of missing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3\n",
    "\n",
    "Now I will try to intentionally introduce errors into my code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Forgetting to import pandas\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# Forgetting to import pandas\n",
    "\n",
    "pd.read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Me: ***Directly pasted the error message***\n",
    "\n",
    "ChatGPT: The error you're encountering, `NameError: name 'pd' is not defined`, occurs because the `pandas` library (usually abbreviated as `pd`) has not been imported.\n",
    "\n",
    "To fix this, you need to import the `pandas` library at the beginning of your code. Here's how you can do that:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Now you can read the CSV file\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv')\n",
    "```\n",
    "\n",
    "This should resolve the error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 404: Not Found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Mistyping the URL/Filename/Path\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttps://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanics.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Everything/UofT/STA130/.venv/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Everything/UofT/STA130/.venv/lib/python3.11/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/Desktop/Everything/UofT/STA130/.venv/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Everything/UofT/STA130/.venv/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/Desktop/Everything/UofT/STA130/.venv/lib/python3.11/site-packages/pandas/io/common.py:728\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    725\u001b[0m     codecs\u001b[38;5;241m.\u001b[39mlookup_error(errors)\n\u001b[1;32m    727\u001b[0m \u001b[38;5;66;03m# open URLs\u001b[39;00m\n\u001b[0;32m--> 728\u001b[0m ioargs \u001b[38;5;241m=\u001b[39m \u001b[43m_get_filepath_or_buffer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    729\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    730\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    731\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    732\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    733\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    734\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    736\u001b[0m handle \u001b[38;5;241m=\u001b[39m ioargs\u001b[38;5;241m.\u001b[39mfilepath_or_buffer\n\u001b[1;32m    737\u001b[0m handles: \u001b[38;5;28mlist\u001b[39m[BaseBuffer]\n",
      "File \u001b[0;32m~/Desktop/Everything/UofT/STA130/.venv/lib/python3.11/site-packages/pandas/io/common.py:384\u001b[0m, in \u001b[0;36m_get_filepath_or_buffer\u001b[0;34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;66;03m# assuming storage_options is to be interpreted as headers\u001b[39;00m\n\u001b[1;32m    383\u001b[0m req_info \u001b[38;5;241m=\u001b[39m urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39mRequest(filepath_or_buffer, headers\u001b[38;5;241m=\u001b[39mstorage_options)\n\u001b[0;32m--> 384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq_info\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m req:\n\u001b[1;32m    385\u001b[0m     content_encoding \u001b[38;5;241m=\u001b[39m req\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Encoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m content_encoding \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgzip\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    387\u001b[0m         \u001b[38;5;66;03m# Override compression based on Content-Encoding header\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Everything/UofT/STA130/.venv/lib/python3.11/site-packages/pandas/io/common.py:289\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;124;03mLazy-import wrapper for stdlib urlopen, as that imports a big chunk of\u001b[39;00m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;124;03mthe stdlib.\u001b[39;00m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01murllib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrequest\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43murllib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/urllib/request.py:216\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    215\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[0;32m--> 216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/urllib/request.py:525\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m processor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_response\u001b[38;5;241m.\u001b[39mget(protocol, []):\n\u001b[1;32m    524\u001b[0m     meth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(processor, meth_name)\n\u001b[0;32m--> 525\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/urllib/request.py:634\u001b[0m, in \u001b[0;36mHTTPErrorProcessor.http_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;66;03m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;66;03m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m):\n\u001b[0;32m--> 634\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhdrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    637\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/urllib/request.py:563\u001b[0m, in \u001b[0;36mOpenerDirector.error\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_err:\n\u001b[1;32m    562\u001b[0m     args \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mdict\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp_error_default\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m+\u001b[39m orig_args\n\u001b[0;32m--> 563\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/urllib/request.py:496\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[1;32m    495\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[0;32m--> 496\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    497\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    498\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/urllib/request.py:643\u001b[0m, in \u001b[0;36mHTTPDefaultErrorHandler.http_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    642\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttp_error_default\u001b[39m(\u001b[38;5;28mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[0;32m--> 643\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(req\u001b[38;5;241m.\u001b[39mfull_url, code, msg, hdrs, fp)\n",
      "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 404: Not Found"
     ]
    }
   ],
   "source": [
    "# Mistyping the URL/Filename/Path\n",
    "import pandas as pd\n",
    "pd.read_csv('https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanics.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Me: ***Directly pasted the error message***\n",
    "\n",
    "ChatGPT: The error you're encountering, `HTTPError: HTTP Error 404: Not Found`, indicates that the URL you're trying to access does not exist. This usually happens due to a typo in the URL or because the resource has been moved or deleted.\n",
    "\n",
    "In this case, it seems you've mistyped the URL. The correct URL for the Titanic dataset from Seaborn should be:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Correct URL\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv')\n",
    "```\n",
    "\n",
    "Notice the correct filename is `titanic.csv`, not `titanics.csv`. This should resolve the issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_titanic' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Using a dataframe that has not been defined\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mdf_titanic\u001b[49m\u001b[38;5;241m.\u001b[39mdescribe()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_titanic' is not defined"
     ]
    }
   ],
   "source": [
    "# Using a dataframe that has not been defined\n",
    "df_titanic.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Me: ***Directly pasted the error message***\n",
    "\n",
    "ChatGPT: The error `NameError: name 'df_titanic' is not defined` occurs because the variable `df_titanic` is being used without being defined first. In your code, you likely read the Titanic dataset into a different variable, such as `df`.\n",
    "\n",
    "To fix this, make sure you reference the correct dataframe variable name. Here's how you can modify your code:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset\n",
    "df_titanic = pd.read_csv('https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv')\n",
    "\n",
    "# Now you can describe the dataset\n",
    "df_titanic.describe()\n",
    "```\n",
    "\n",
    "Make sure that the dataframe variable (`df_titanic` in this case) is correctly defined before you try to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (398712648.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[4], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    df_titanic.describe(\u001b[0m\n\u001b[0m                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "# Forget a parenthesis\n",
    "df_titanic.describe("
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Me: ***Directly pasted the error message***\n",
    "\n",
    "ChatGPT: The error `SyntaxError: incomplete input` occurs because the code is missing a closing parenthesis or some other required element that would complete the syntax.\n",
    "\n",
    "In your example, it seems that the line was cut off or incomplete. If you want to simply run `df_titanic.describe()`, make sure the parentheses are properly closed.\n",
    "\n",
    "Here's the corrected code:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset\n",
    "df_titanic = pd.read_csv('https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv')\n",
    "\n",
    "# Describe the dataset\n",
    "df_titanic.describe()  # Complete function call\n",
    "```\n",
    "\n",
    "This should work without the syntax error. If you're intending to pass arguments inside `describe()`, make sure they are complete as well.\n",
    "\n",
    "> I really like how ChatGPT reminded me to make sure the arguments passed in descrive() are comeplete as well, haha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SeriesGroupBy' object has no attribute 'describle'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Mistype chained functions\u001b[39;00m\n\u001b[1;32m      2\u001b[0m df_titanic \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mdf_titanic\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msex\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43malive\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdescrible\u001b[49m()\n",
      "File \u001b[0;32m~/Desktop/Everything/UofT/STA130/.venv/lib/python3.11/site-packages/pandas/core/groupby/groupby.py:1363\u001b[0m, in \u001b[0;36mGroupBy.__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m   1360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj:\n\u001b[1;32m   1361\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[attr]\n\u001b[0;32m-> 1363\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m   1364\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1365\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'SeriesGroupBy' object has no attribute 'describle'"
     ]
    }
   ],
   "source": [
    "# Mistype chained functions\n",
    "df_titanic = pd.read_csv('https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv')\n",
    "df_titanic.groupby(\"sex\")[\"alive\"].describle()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ChatGPT: The error you're encountering, `AttributeError: 'SeriesGroupBy' object has no attribute 'describle'`, is due to a typo in the function name. The correct function name is `.describe()`, not `.describle()`.\n",
    "\n",
    "Here's the corrected code:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset\n",
    "df_titanic = pd.read_csv('https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv')\n",
    "\n",
    "# Group by 'sex' and describe the 'alive' column\n",
    "df_titanic.groupby(\"sex\")[\"alive\"].describe()\n",
    "```\n",
    "\n",
    "This should resolve the issue, and you'll get a summary of the `alive` column grouped by `sex`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Column not found: Age'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Wrong column name\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mdf_titanic\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msex\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mAge\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mdescribe()\n",
      "File \u001b[0;32m~/Desktop/Everything/UofT/STA130/.venv/lib/python3.11/site-packages/pandas/core/groupby/generic.py:1951\u001b[0m, in \u001b[0;36mDataFrameGroupBy.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1944\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(key) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1945\u001b[0m     \u001b[38;5;66;03m# if len == 1, then it becomes a SeriesGroupBy and this is actually\u001b[39;00m\n\u001b[1;32m   1946\u001b[0m     \u001b[38;5;66;03m# valid syntax, so don't raise\u001b[39;00m\n\u001b[1;32m   1947\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1948\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot subset columns with a tuple with more than one element. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1949\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse a list instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1950\u001b[0m     )\n\u001b[0;32m-> 1951\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Everything/UofT/STA130/.venv/lib/python3.11/site-packages/pandas/core/base.py:244\u001b[0m, in \u001b[0;36mSelectionMixin.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj:\n\u001b[0;32m--> 244\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumn not found: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    245\u001b[0m     ndim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj[key]\u001b[38;5;241m.\u001b[39mndim\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gotitem(key, ndim\u001b[38;5;241m=\u001b[39mndim)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Column not found: Age'"
     ]
    }
   ],
   "source": [
    "# Wrong column name\n",
    "\n",
    "df_titanic.groupby(\"sex\")[\"Age\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ChatGPT: The error `KeyError: 'Column not found: Age'` indicates that there is no column named `\"Age\"` in your dataframe, likely because the column name is case-sensitive.\n",
    "\n",
    "In the Titanic dataset, the correct column name is `\"age\"`, not `\"Age\"`. Here's the corrected code:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset\n",
    "df_titanic = pd.read_csv('https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv')\n",
    "\n",
    "# Group by 'sex' and describe the 'age' column\n",
    "df_titanic.groupby(\"sex\")[\"age\"].describe()\n",
    "```\n",
    "\n",
    "Make sure that column names exactly match the ones in the dataframe. You can always check the column names using `df_titanic.columns` to avoid such errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sex' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Forgetting quotation marks\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m df_titanic\u001b[38;5;241m.\u001b[39mgroupby(\u001b[43msex\u001b[49m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124malive\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdescribe()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sex' is not defined"
     ]
    }
   ],
   "source": [
    "# Forgetting quotation marks\n",
    "\n",
    "df_titanic.groupby(sex)['alive'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ChatGPT: The `NameError: name 'sex' is not defined` occurs because you forgot to enclose the column name `sex` in quotation marks. In Python, column names should be provided as strings.\n",
    "\n",
    "Here's the corrected code:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset\n",
    "df_titanic = pd.read_csv('https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv')\n",
    "\n",
    "# Group by 'sex' and describe the 'alive' column\n",
    "df_titanic.groupby('sex')['alive'].describe()\n",
    "```\n",
    "\n",
    "By enclosing `sex` in quotation marks, you indicate that it is a string representing the column name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison between ChatGPT and using Google Search (8.3)\n",
    "\n",
    "As a person that doesn't really use ChatGPT and always preferred to use Google Searches or StackOverflow to answer my questions while programming or coding, I can really feel the different without even trying to search these errors up on Google. And I think it could really be summaried into one word: **\"context\"**\n",
    "\n",
    "ChatGPT's ability to add context into the questions and its answer significantly helps improve the efficiency of it's answers, especially when it comes to questions relating to coding. Using the examples above, for each of the questions I've asked ChatGPT, not only was it able to identify where the problem with the code was, but also give a correct fix for the code with all the details, such as the columns that are being accessed, the link to the dataframe, and the chain of methods being called. When doing Google searches, it is really hard to include enough context into the search, such as including the entire error report, or parts of the code, ~~unless posting the question on StackOverflow, which could be very slow since you need to wait for someone to answer...~~, while ChatGPT is able to include all of the context given and formulate a fix for whatever error is being thrown at it.\n",
    "\n",
    "For example, the 6th error that was intentionally introduced to ChatGPT included using a column name that doesn't exist. The main error call was `KeyError: 'Column not found: Age'`, if this was searched on Google, there isn't enough context to identify what went wrong, since the Google search wouldn't know what the real/correct column name is. But ChatGPT is able to combine the question with context previously established, and quickly identify the mistyped column name and provide a full fix.\n",
    "\n",
    "That brings me to my next point, providing a \"full fix\". When searching on Google, there should be lots of people encountering very similar issues, but it could be very rare where their code is exactly the same as yours, that what they wanted to achieve was the same. Since the same error could be presented while having completely different code, for example, both the 7th and 3rd errors introduced both had the `NameError: name 'something' is not defined` error. Without context, it will be difficult to use a Google search to know exactly how to fix the issue. But with context, ChatGPT is able to locate exactly where, what, and how things went wrong and provide a fix.\n",
    "\n",
    "To close off, I would like to one again mention how ChatGPT told me to be careful of not mistyping the arguments passed into .describe() when creating the 4th error, having mistyped/forgetting a parenthesis. It really shows how ChatGPT ability to take the clumsyness and human error into account when formulating it's responses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 9: YES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full summary of conversations with ChatGPT:\n",
    "\n",
    "**Questions 1-8.2:** https://chatgpt.com/share/66e3bb1c-ccd8-800d-9ef5-84efc1c4a0ad\n",
    "\n",
    "**Question 8.3:** https://chatgpt.com/share/66e3bb3c-6948-800d-855b-f0cf54f6c254"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
