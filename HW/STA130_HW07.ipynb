{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STA130 Homework 07"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ChatGPT Chat log links:\n",
    "\n",
    "Clarification and review on indicator variables: https://chatgpt.com/share/67349492-9dbc-800d-b896-878d502709af\n",
    "\n",
    "MLR and Overfitting: https://chatgpt.com/share/6737e3b6-df08-800d-af4e-f23cabc1210f\n",
    "\n",
    "Queston 5 to 9 Focus: https://chatgpt.com/share/6737e390-9074-800d-87ea-5a157692473c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "\n",
    "### 1. Difference between SLR and MLR\n",
    "\n",
    "Simple Linear Regression, or SLR, is a statistical model that attemps to estimate the relationship between a predicator (independent) variable and a outcome (dependent) variable. SLR models a one-on-one relationship, where an input $X$ gives an output $Y$. An indicator variable might also be involved in SLR model, representing a difference between groups under a similar $X \\sim Y$ relationship.\n",
    "\n",
    "An example linear form of a SLR model can be:\n",
    "\n",
    "$$y = \\beta_0 + \\beta_1 x + \\epsilon$$\n",
    "\n",
    "Where $y$ is the outcome and $x$ is the predictor variable, and $\\beta_0$ and $\\beta_1$ are the coefficients.\n",
    "\n",
    "Multiple Linear Regression, or MLR, is also a statistical model that estimates the relationship between predicator and outcome variables, except in MLR, instead of a one-on-one relationship, multiple predicator variables may be used to predict one outcome variable. \n",
    "\n",
    "An example linear form of a MLR model can be:\n",
    "\n",
    "$$y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\beta_3 x_3 + \\epsilon$$\n",
    "\n",
    "Where $x_1$ $x_2$ $x_3$ are each different predictor variables.\n",
    "\n",
    "The benefits of MLR over SLR are that is it able to model the effect of multiple predictor variables on the outcome variable simultaneously. Often time when trying to model these relationships, there are way more than one variables that effect the outcome simultaneously. While SLR can only model the relationship between one variable and another, MLR can model much more complex relationships through interactions, polynomial terms, or even transformations to model non-linear and non-additive relationships. (We will explain what additive and synergistic relationships are soon)\n",
    "\n",
    "### 2. Difference between continuous variable and indicator variable in an SLR model\n",
    "\n",
    "The difference between a continuous variable and an indicator variable is that, with a continuous variable, we are modelling how much variation there is in $Y$ in comparison to how much variation there is in $X$. While for an indivator variable, we are only looking at how $Y$ changes (or the difference in $Y$) between different indicator groups.\n",
    "\n",
    "The linear form of a SLR model with a continuous variable looks something like:\n",
    "\n",
    "$$y = \\beta_0 + \\beta_1 x_1 + \\epsilon$$\n",
    "\n",
    "Where $\\beta_1$ is the coefficient that measures the defines the magnitude of significance changes in $X$ has on $Y$ (or just the slope), and $\\beta_0$ is the y-intercept.\n",
    "\n",
    "The linear form of a SLR model with an indicator variable look something like:\n",
    "\n",
    "$$y = \\beta_0 + \\beta_1 1_\\text{[x=\"A\"]} + \\epsilon$$\n",
    "\n",
    "Where $\\beta_0$ is the outcome variable for when $x$ is \"A\", and $\\beta_1$ is the difference between the outcome variable for when $x$ is \"A\" and when $x$ is \"B\".\n",
    "\n",
    "### 3. When an indicator variable is introduced alongside a continuous variable to create a MLR model\n",
    "\n",
    "When we have an indicator variable introduced alongside a continuous variable in an SLR model to create an MLR model, we are essentially creating parallel linear functions, where one of the functions describe the relationship between the continuous predictor and the outcome under one situation, and the other function describes the relationship under another situation.\n",
    "\n",
    "The linear form of a SLR model looks like:\n",
    "\n",
    "$$y = \\beta_0 + \\beta_1 x_1 + \\epsilon$$\n",
    "\n",
    "Where $\\beta_1$ is the coefficient that measures the defines the magnitude of significance changes in $X$ has on $Y$ (or just the slope), and $\\beta_0$ is the y-intercept.\n",
    "\n",
    "When introducing a indicator variable along with it, the linear form looks like:\n",
    "\n",
    "$$y = \\beta_0 + \\beta_1 x_1 + \\beta_2 1_\\text{[x=\"A\"]} + \\epsilon$$\n",
    "\n",
    "Where the $\\beta_2$ coefficient represents the difference between the intercepts of the parallel lines. As a result, we have two parallel lines with a slope of $\\beta_1$, one with a y-intercept of $\\beta_0$, the other with a y-intercept of $\\beta_2$.\n",
    "\n",
    "### 4. The effect of adding an interaction between a continuous and an indicator variable in MLR models\n",
    "\n",
    "This is similar to the previous case of introducing an indivator variable alongside a continuous variable, but this time we are talking about introducing the indicator variable as an interaction with a continuous variable. Therefore, the result of the model specification is not just mutliple parallel lines, but rather multiple non-parallel linear functions, with one line representing the relationship between the variation in the continuous predictor variable in one indicator variable group, and other lines representing that relationship in other indicator groups.\n",
    "\n",
    "The linear form for this case looks something like:\n",
    "\n",
    "$$y = \\beta_0 + \\beta_1 x_1 + \\beta_2 1_\\text{[K=\"A\"]}x_1$$\n",
    "\n",
    "Where K is the indicator variable (as in \"Kategory\"). So now, when K is not A, we end up with $y = \\beta_0 + \\beta_1 x_1$, where $\\beta_0$ is the y-intercept and $\\beta_1$ is the coefficient for the continuous variable $x_1$, or the slope. And when K is A, we end up with $y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_1$, where $\\beta_2$ acts as a modifier for the slope.\n",
    "\n",
    "### 5. The behavior of a MLR model based only on indicator variables derived from a non-binary categorical variable\n",
    "\n",
    "When we have a MLR model based purely on indicator variables derived from non-binary categorical variables, we use a dummy variable that reflects a value of $1$ when the observation matches the given category, and $0$ when it does not:\n",
    "\n",
    "$$Dummy = 1_\\text{[K='Category']}$$\n",
    "\n",
    "When K is \"Category\", this dummy variable is 1, when it's not, the dummy variable is 0. For a categorical variable with $P$ amount of categories, we will need $P-1$ amount of these dummy binary encoders to represent all of the categories.\n",
    "\n",
    "The linear form might look something like:\n",
    "\n",
    "$$y = \\beta_0 + \\beta_1 K_\\text{k1} + \\beta_2 K_\\text{k2} + \\beta_3 K_\\text{k3} + \\epsilon$$\n",
    "\n",
    "Where each of $k1, k2, k3$ and an ommitted $k4$ are a different kategory. As such, we may realize that the model does not have a slope, since all of the predictors are indicators, we are comparing the relationship between the mean values of $Y$ and different indicator kategories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "The main keypoint to be discussed in this question and the given scenario is about the use of interactions between variables. When we talk about the difference between a model in terms of how variables are dealt with, there are two big types we can look at for interactioons.\n",
    "\n",
    "- Additive, when there is no interactions between the multiple predictor variables. The predictor variables have no influence on each other, the values of one variable has no effect on how the other variable effects the outcome. The linear form of an additive model is shown below, where $x_1$ and $x_2$ are the two predictor variables. Notice how each of the predictors are added together, and there are no other relationships between the predictors.\n",
    "\n",
    "$$y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\epsilon$$\n",
    "\n",
    "- Synergistic, when there are interactions between the multiple predictor variables. The predictor variable influence each other, in a sense that the value of one variable influence how much other variables effect the outcomes. The linear form of a synergistic model is shown below. Notice how the final $\\beta_3$ term involves a multiplication between the two predictors, this signifies an interaction.\n",
    "\n",
    "$$y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\beta_3 (x_1 \\times x_2) + \\epsilon$$\n",
    "\n",
    "Since our scenario is about the amount of money spent on TV and online platforms for advertising, both of the predictor variables are continuous, and our outcome could be any measure of the effect of the advertising campaigns, such as sales of advertised sports equipment, therefore:\n",
    "\n",
    "For synergistic models, since the magnitude of influence over the outcome of one variable may be influenced by another variable, say, either amplified or reduced, what we get will no longer be a real \"linear\" relationship, but rather a twisting surface/non-linear relationship between the predictors and the outcomes. In other words, the slope coefficient for a certain variable changes as the value of the other variable changes.\n",
    "\n",
    "To explain this, we may notice with the above linear form in mind that:\n",
    "\n",
    "For per unit change in $x_1$, $y$ changes by $\\beta_3 x_2 + \\beta_1$, meaning that the change in $y$ caused by $x_1$ depends on the value of $x_2$.\n",
    "\n",
    "And vice versa: \n",
    "\n",
    "For per unit change in $x_2$, $y$ changes by $\\beta_3 x_1 + \\beta_2$, meaning that the change in $y$ caused by $x_2$ depends on the value of $x_1$.\n",
    "\n",
    "These relationships between $x_1$ and $x_2$ explains and models the relationship between the effectiveness a TV ad maybe have depends on the amount spent on online advertising, and vice versa. After fitting for a value for each of the $\\beta$'s, we can make predictions by simply inputting the predictors into the linear form addressed above.\n",
    "\n",
    "Now, say that we change the predictor variables, rather than considering two continuous variables, suppose the become categorized simply by either \"high\" or \"low\". This makes these predictor variables be purely composed of binary indicator variables. Such as setup could be useful to capture the mean changes and effects are different based on whether or not the indicators are \"high\", represeted as a $1$, or \"low\", represented as a $0$.\n",
    "\n",
    "Under a additive model, having a model purely composed of these indicator variables become:\n",
    "\n",
    "$$y = \\beta_0 + \\beta_1 S_1 + \\beta_2 S_2 + \\epsilon$$\n",
    "\n",
    "We can see that the effects the indicator variables $S_1$ and $S_2$ have on the outcome are purely additive.\n",
    "\n",
    "Under a synergistic model, the linear form would look something like:\n",
    "\n",
    "$$y = \\beta_0 + \\beta_1 S_1 + \\beta_2 S_2 + \\beta_3 (S_1 \\times S_2)$$\n",
    "\n",
    "From the linear form above, we can see that the $\\beta_3$ coefficient depends on both $S_1$ and $S_2$ to be 1, or being a \"high\" indicator. As such, the $\\beta_3$ captures that **EXTRA** part of influence on the outcome variable, as it is only activated when both predictors are 1, in addition to the additive model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm honestly not quite understanding the gist of this question and what interpretations I'm supposed to make... The models I've built don't really seem to be working well and I keep encountering errors when I try to add more predictors into the specification...\n",
    "\n",
    "ChatGPT Chat history link for specific errors and to show how difficult this was for me:\n",
    "\n",
    "https://chatgpt.com/share/6737e3fb-812c-800d-bed7-48623f4f60fe\n",
    "\n",
    "For my regression model, I want to look at how the status of a person feeling lonely is related to their social time with others, their age, their student status, and their gender. Logistic regression is great for looking at binary outcomes based on predictors.\n",
    "\n",
    "In other words, the logistic regression model predicts a probability of a binary outcome variable being $1$, or having positive outcome, given the values of predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3c/3vwv00w96dz2b2bzgplw8fym0000gn/T/ipykernel_85358/3105336104.py:4: DtypeWarning:\n",
      "\n",
      "Columns (408,1001,1002,1006,1007,1008,1080,1113,1115,1116,1117,1118,1119,1120,1121,1124,1125,1126,1127,1128,1213,1214,1215,1216,1217,1218,1342,1343,1344,1345,1346,1347,1348,1349,1390,1391,1393,1463,1549,1552,1555,1558,1561) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>DEMO_age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4210.000000</td>\n",
       "      <td>4210.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5782.627316</td>\n",
       "      <td>39.242755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3294.779016</td>\n",
       "      <td>15.423012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2964.750000</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5824.500000</td>\n",
       "      <td>34.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8666.500000</td>\n",
       "      <td>51.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>11430.000000</td>\n",
       "      <td>90.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              index     DEMO_age\n",
       "count   4210.000000  4210.000000\n",
       "mean    5782.627316    39.242755\n",
       "std     3294.779016    15.423012\n",
       "min        4.000000    16.000000\n",
       "25%     2964.750000    27.000000\n",
       "50%     5824.500000    34.000000\n",
       "75%     8666.500000    51.000000\n",
       "max    11430.000000    90.000000"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "cscs = pd.read_csv('/Users/hayden/Desktop/Everything/UofT/STA130/stat130chat130-main/CP/CSCS_data_anon.csv')\n",
    "\n",
    "# Keep only the columns we want\n",
    "wanted_columns = ['LONELY_direct', 'CONNECTION_social_time_family_p7d_grouped', 'CONNECTION_social_time_friends_p7d_grouped',\n",
    "                  'CONNECTION_social_time_coworkers_and_classmates_p7d_grouped', 'CONNECTION_social_time_neighbours_p7d_grouped',\n",
    "                  'DEMO_student', 'DEMO_age', 'DEMO_gender']\n",
    "cscs = cscs[wanted_columns].dropna().reset_index()\n",
    "# Remove rows where any column contains the value \"Presented but no response\"\n",
    "cscs = cscs[~cscs.isin([\"Presented but no response\"]).any(axis=1)]\n",
    "cscs.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make our outcome variable binary, I have converted the Loneliness status from the dataset into binary results based on how much lonliness they're experiencing, the specifications are as below:\n",
    "\n",
    "I also had to do some type conversions... This took a while to troubleshoot with ChatGPT... See chatlog above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3c/3vwv00w96dz2b2bzgplw8fym0000gn/T/ipykernel_85358/4068728224.py:6: FutureWarning:\n",
      "\n",
      "Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>LONELY_direct</th>\n",
       "      <th>CONNECTION_social_time_family_p7d_grouped</th>\n",
       "      <th>CONNECTION_social_time_friends_p7d_grouped</th>\n",
       "      <th>CONNECTION_social_time_coworkers_and_classmates_p7d_grouped</th>\n",
       "      <th>CONNECTION_social_time_neighbours_p7d_grouped</th>\n",
       "      <th>DEMO_student</th>\n",
       "      <th>DEMO_age</th>\n",
       "      <th>DEMO_gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5 or more hours</td>\n",
       "      <td>1 to 4 hours</td>\n",
       "      <td>1 to 4 hours</td>\n",
       "      <td>1 to 4 hours</td>\n",
       "      <td>No</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Man</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Less than 1 hour</td>\n",
       "      <td>1 to 4 hours</td>\n",
       "      <td>Less than 1 hour</td>\n",
       "      <td>No time</td>\n",
       "      <td>No</td>\n",
       "      <td>55.0</td>\n",
       "      <td>Woman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>No time</td>\n",
       "      <td>1 to 4 hours</td>\n",
       "      <td>No time</td>\n",
       "      <td>No time</td>\n",
       "      <td>No</td>\n",
       "      <td>66.0</td>\n",
       "      <td>Man</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>5 or more hours</td>\n",
       "      <td>1 to 4 hours</td>\n",
       "      <td>1 to 4 hours</td>\n",
       "      <td>1 to 4 hours</td>\n",
       "      <td>No</td>\n",
       "      <td>27.0</td>\n",
       "      <td>Woman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>No time</td>\n",
       "      <td>5 or more hours</td>\n",
       "      <td>No time</td>\n",
       "      <td>Less than 1 hour</td>\n",
       "      <td>No</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Woman</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  LONELY_direct CONNECTION_social_time_family_p7d_grouped  \\\n",
       "0      4              0                           5 or more hours   \n",
       "1      5              0                          Less than 1 hour   \n",
       "2      8              1                                   No time   \n",
       "3     10              0                           5 or more hours   \n",
       "4     11              0                                   No time   \n",
       "\n",
       "  CONNECTION_social_time_friends_p7d_grouped  \\\n",
       "0                               1 to 4 hours   \n",
       "1                               1 to 4 hours   \n",
       "2                               1 to 4 hours   \n",
       "3                               1 to 4 hours   \n",
       "4                            5 or more hours   \n",
       "\n",
       "  CONNECTION_social_time_coworkers_and_classmates_p7d_grouped  \\\n",
       "0                                       1 to 4 hours            \n",
       "1                                   Less than 1 hour            \n",
       "2                                            No time            \n",
       "3                                       1 to 4 hours            \n",
       "4                                            No time            \n",
       "\n",
       "  CONNECTION_social_time_neighbours_p7d_grouped DEMO_student  DEMO_age  \\\n",
       "0                                  1 to 4 hours           No      30.0   \n",
       "1                                       No time           No      55.0   \n",
       "2                                       No time           No      66.0   \n",
       "3                                  1 to 4 hours           No      27.0   \n",
       "4                              Less than 1 hour           No      49.0   \n",
       "\n",
       "  DEMO_gender  \n",
       "0         Man  \n",
       "1       Woman  \n",
       "2         Man  \n",
       "3       Woman  \n",
       "4       Woman  "
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make LONELY_direct a binary variable based on responses\n",
    "cscs['LONELY_direct'] = cscs['LONELY_direct'].replace('None of the time (e.g., 0 days)', 0)\n",
    "cscs['LONELY_direct'] = cscs['LONELY_direct'].replace('Rarely (e.g. less than 1 day)', 0)\n",
    "cscs['LONELY_direct'] = cscs['LONELY_direct'].replace('Some or a little of the time (e.g. 1-2 days)', 1)\n",
    "cscs['LONELY_direct'] = cscs['LONELY_direct'].replace('Occasionally or a moderate amount of time (e.g. 3-4 days)', 1)\n",
    "cscs['LONELY_direct'] = cscs['LONELY_direct'].replace('All of the time (e.g. 5-7 days)]', 1)\n",
    "\n",
    "# Convert all numeric columns to numeric (was object)\n",
    "cscs['LONELY_direct'] = pd.to_numeric(cscs['LONELY_direct'], errors='coerce')\n",
    "cscs = cscs[pd.to_numeric(cscs['LONELY_direct'], errors='coerce').notna()]\n",
    "cscs['DEMO_age'] = pd.to_numeric(cscs['DEMO_age'], errors='coerce')\n",
    "cscs['LONELY_direct'] = cscs['LONELY_direct'].astype(int)\n",
    "\n",
    "# preview?\n",
    "cscs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like I said, I tried adding some more predictors, like numeric values, but it just won't let me, ChatGPT said it might have been too complicated?\n",
    "\n",
    "So for the first additive model, I'm adding up the indicator variables from the `CONNECTION_social_time` columns to see if there's a relationship between these categorical indicators and the Loneliness status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.681985\n",
      "         Iterations 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>LONELY_direct</td>  <th>  No. Observations:  </th>  <td>  4210</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td>  4197</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>    12</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Fri, 15 Nov 2024</td> <th>  Pseudo R-squ.:     </th>  <td>0.01489</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>18:51:31</td>     <th>  Log-Likelihood:    </th> <td> -2871.2</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -2914.6</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>2.054e-13</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                                           <td></td>                                             <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                                                                          <td>    0.0214</td> <td>    0.098</td> <td>    0.219</td> <td> 0.827</td> <td>   -0.170</td> <td>    0.213</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(CONNECTION_social_time_family_p7d_grouped)[T.5 or more hours]</th>                    <td>   -0.3149</td> <td>    0.082</td> <td>   -3.859</td> <td> 0.000</td> <td>   -0.475</td> <td>   -0.155</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(CONNECTION_social_time_family_p7d_grouped)[T.Less than 1 hour]</th>                   <td>   -0.0294</td> <td>    0.090</td> <td>   -0.328</td> <td> 0.743</td> <td>   -0.205</td> <td>    0.147</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(CONNECTION_social_time_family_p7d_grouped)[T.No time]</th>                            <td>    0.2194</td> <td>    0.122</td> <td>    1.793</td> <td> 0.073</td> <td>   -0.020</td> <td>    0.459</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(CONNECTION_social_time_friends_p7d_grouped)[T.5 or more hours]</th>                   <td>    0.0149</td> <td>    0.092</td> <td>    0.162</td> <td> 0.871</td> <td>   -0.165</td> <td>    0.194</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(CONNECTION_social_time_friends_p7d_grouped)[T.Less than 1 hour]</th>                  <td>   -0.0499</td> <td>    0.084</td> <td>   -0.596</td> <td> 0.551</td> <td>   -0.214</td> <td>    0.114</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(CONNECTION_social_time_friends_p7d_grouped)[T.No time]</th>                           <td>    0.0757</td> <td>    0.111</td> <td>    0.683</td> <td> 0.495</td> <td>   -0.142</td> <td>    0.293</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(CONNECTION_social_time_coworkers_and_classmates_p7d_grouped)[T.5 or more hours]</th>  <td>   -0.1275</td> <td>    0.104</td> <td>   -1.231</td> <td> 0.218</td> <td>   -0.330</td> <td>    0.075</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(CONNECTION_social_time_coworkers_and_classmates_p7d_grouped)[T.Less than 1 hour]</th> <td>   -0.1109</td> <td>    0.090</td> <td>   -1.231</td> <td> 0.218</td> <td>   -0.287</td> <td>    0.066</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(CONNECTION_social_time_coworkers_and_classmates_p7d_grouped)[T.No time]</th>          <td>    0.1085</td> <td>    0.095</td> <td>    1.138</td> <td> 0.255</td> <td>   -0.078</td> <td>    0.295</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(CONNECTION_social_time_neighbours_p7d_grouped)[T.5 or more hours]</th>                <td>    0.3656</td> <td>    0.125</td> <td>    2.930</td> <td> 0.003</td> <td>    0.121</td> <td>    0.610</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(CONNECTION_social_time_neighbours_p7d_grouped)[T.Less than 1 hour]</th>               <td>    0.0785</td> <td>    0.088</td> <td>    0.895</td> <td> 0.371</td> <td>   -0.093</td> <td>    0.250</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(CONNECTION_social_time_neighbours_p7d_grouped)[T.No time]</th>                        <td>    0.4046</td> <td>    0.096</td> <td>    4.229</td> <td> 0.000</td> <td>    0.217</td> <td>    0.592</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}                                                                            &  LONELY\\_direct  & \\textbf{  No. Observations:  } &     4210    \\\\\n",
       "\\textbf{Model:}                                                                                    &      Logit       & \\textbf{  Df Residuals:      } &     4197    \\\\\n",
       "\\textbf{Method:}                                                                                   &       MLE        & \\textbf{  Df Model:          } &       12    \\\\\n",
       "\\textbf{Date:}                                                                                     & Fri, 15 Nov 2024 & \\textbf{  Pseudo R-squ.:     } &  0.01489    \\\\\n",
       "\\textbf{Time:}                                                                                     &     18:51:31     & \\textbf{  Log-Likelihood:    } &   -2871.2   \\\\\n",
       "\\textbf{converged:}                                                                                &       True       & \\textbf{  LL-Null:           } &   -2914.6   \\\\\n",
       "\\textbf{Covariance Type:}                                                                          &    nonrobust     & \\textbf{  LLR p-value:       } & 2.054e-13   \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                                                                                                   & \\textbf{coef} & \\textbf{std err} & \\textbf{z} & \\textbf{P$> |$z$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}                                                                                 &       0.0214  &        0.098     &     0.219  &         0.827        &       -0.170    &        0.213     \\\\\n",
       "\\textbf{C(CONNECTION\\_social\\_time\\_family\\_p7d\\_grouped)[T.5 or more hours]}                      &      -0.3149  &        0.082     &    -3.859  &         0.000        &       -0.475    &       -0.155     \\\\\n",
       "\\textbf{C(CONNECTION\\_social\\_time\\_family\\_p7d\\_grouped)[T.Less than 1 hour]}                     &      -0.0294  &        0.090     &    -0.328  &         0.743        &       -0.205    &        0.147     \\\\\n",
       "\\textbf{C(CONNECTION\\_social\\_time\\_family\\_p7d\\_grouped)[T.No time]}                              &       0.2194  &        0.122     &     1.793  &         0.073        &       -0.020    &        0.459     \\\\\n",
       "\\textbf{C(CONNECTION\\_social\\_time\\_friends\\_p7d\\_grouped)[T.5 or more hours]}                     &       0.0149  &        0.092     &     0.162  &         0.871        &       -0.165    &        0.194     \\\\\n",
       "\\textbf{C(CONNECTION\\_social\\_time\\_friends\\_p7d\\_grouped)[T.Less than 1 hour]}                    &      -0.0499  &        0.084     &    -0.596  &         0.551        &       -0.214    &        0.114     \\\\\n",
       "\\textbf{C(CONNECTION\\_social\\_time\\_friends\\_p7d\\_grouped)[T.No time]}                             &       0.0757  &        0.111     &     0.683  &         0.495        &       -0.142    &        0.293     \\\\\n",
       "\\textbf{C(CONNECTION\\_social\\_time\\_coworkers\\_and\\_classmates\\_p7d\\_grouped)[T.5 or more hours]}  &      -0.1275  &        0.104     &    -1.231  &         0.218        &       -0.330    &        0.075     \\\\\n",
       "\\textbf{C(CONNECTION\\_social\\_time\\_coworkers\\_and\\_classmates\\_p7d\\_grouped)[T.Less than 1 hour]} &      -0.1109  &        0.090     &    -1.231  &         0.218        &       -0.287    &        0.066     \\\\\n",
       "\\textbf{C(CONNECTION\\_social\\_time\\_coworkers\\_and\\_classmates\\_p7d\\_grouped)[T.No time]}          &       0.1085  &        0.095     &     1.138  &         0.255        &       -0.078    &        0.295     \\\\\n",
       "\\textbf{C(CONNECTION\\_social\\_time\\_neighbours\\_p7d\\_grouped)[T.5 or more hours]}                  &       0.3656  &        0.125     &     2.930  &         0.003        &        0.121    &        0.610     \\\\\n",
       "\\textbf{C(CONNECTION\\_social\\_time\\_neighbours\\_p7d\\_grouped)[T.Less than 1 hour]}                 &       0.0785  &        0.088     &     0.895  &         0.371        &       -0.093    &        0.250     \\\\\n",
       "\\textbf{C(CONNECTION\\_social\\_time\\_neighbours\\_p7d\\_grouped)[T.No time]}                          &       0.4046  &        0.096     &     4.229  &         0.000        &        0.217    &        0.592     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{Logit Regression Results}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:          LONELY_direct   No. Observations:                 4210\n",
       "Model:                          Logit   Df Residuals:                     4197\n",
       "Method:                           MLE   Df Model:                           12\n",
       "Date:                Fri, 15 Nov 2024   Pseudo R-squ.:                 0.01489\n",
       "Time:                        18:51:31   Log-Likelihood:                -2871.2\n",
       "converged:                       True   LL-Null:                       -2914.6\n",
       "Covariance Type:            nonrobust   LLR p-value:                 2.054e-13\n",
       "======================================================================================================================================================\n",
       "                                                                                         coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
       "Intercept                                                                              0.0214      0.098      0.219      0.827      -0.170       0.213\n",
       "C(CONNECTION_social_time_family_p7d_grouped)[T.5 or more hours]                       -0.3149      0.082     -3.859      0.000      -0.475      -0.155\n",
       "C(CONNECTION_social_time_family_p7d_grouped)[T.Less than 1 hour]                      -0.0294      0.090     -0.328      0.743      -0.205       0.147\n",
       "C(CONNECTION_social_time_family_p7d_grouped)[T.No time]                                0.2194      0.122      1.793      0.073      -0.020       0.459\n",
       "C(CONNECTION_social_time_friends_p7d_grouped)[T.5 or more hours]                       0.0149      0.092      0.162      0.871      -0.165       0.194\n",
       "C(CONNECTION_social_time_friends_p7d_grouped)[T.Less than 1 hour]                     -0.0499      0.084     -0.596      0.551      -0.214       0.114\n",
       "C(CONNECTION_social_time_friends_p7d_grouped)[T.No time]                               0.0757      0.111      0.683      0.495      -0.142       0.293\n",
       "C(CONNECTION_social_time_coworkers_and_classmates_p7d_grouped)[T.5 or more hours]     -0.1275      0.104     -1.231      0.218      -0.330       0.075\n",
       "C(CONNECTION_social_time_coworkers_and_classmates_p7d_grouped)[T.Less than 1 hour]    -0.1109      0.090     -1.231      0.218      -0.287       0.066\n",
       "C(CONNECTION_social_time_coworkers_and_classmates_p7d_grouped)[T.No time]              0.1085      0.095      1.138      0.255      -0.078       0.295\n",
       "C(CONNECTION_social_time_neighbours_p7d_grouped)[T.5 or more hours]                    0.3656      0.125      2.930      0.003       0.121       0.610\n",
       "C(CONNECTION_social_time_neighbours_p7d_grouped)[T.Less than 1 hour]                   0.0785      0.088      0.895      0.371      -0.093       0.250\n",
       "C(CONNECTION_social_time_neighbours_p7d_grouped)[T.No time]                            0.4046      0.096      4.229      0.000       0.217       0.592\n",
       "======================================================================================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Additive model\n",
    "linear_model_additive_spec = 'LONELY_direct ~ C(CONNECTION_social_time_family_p7d_grouped) + \\\n",
    "                            C(CONNECTION_social_time_friends_p7d_grouped) + \\\n",
    "                            C(CONNECTION_social_time_coworkers_and_classmates_p7d_grouped) + \\\n",
    "                            C(CONNECTION_social_time_neighbours_p7d_grouped)'\n",
    "log_reg_fit = smf.logit(formula=linear_model_additive_spec, data=cscs).fit()\n",
    "log_reg_fit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not sure if there's much to see here actually... seems pretty crappy, we only have a R-squared of 0.018 and none of the variables have a low enough p-value to suggest evidence against the null hypothesis of no relationship.\n",
    "\n",
    "*Also I don't have the slightest idea how to plot this, I've tried asking ChatGPT and it just doesn't help*\n",
    "\n",
    "I did want to try something else though:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.691550\n",
      "         Iterations 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>LONELY_direct</td>  <th>  No. Observations:  </th>  <td>  4210</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td>  4207</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>     2</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Fri, 15 Nov 2024</td> <th>  Pseudo R-squ.:     </th> <td>0.001073</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>18:51:31</td>     <th>  Log-Likelihood:    </th> <td> -2911.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -2914.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th>  <td>0.04387</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "             <td></td>               <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>              <td>    0.0073</td> <td>    0.096</td> <td>    0.076</td> <td> 0.940</td> <td>   -0.182</td> <td>    0.196</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(DEMO_student)[T.Yes]</th> <td>    0.1999</td> <td>    0.082</td> <td>    2.446</td> <td> 0.014</td> <td>    0.040</td> <td>    0.360</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>DEMO_age</th>               <td>    0.0009</td> <td>    0.002</td> <td>    0.405</td> <td> 0.685</td> <td>   -0.003</td> <td>    0.005</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}          &  LONELY\\_direct  & \\textbf{  No. Observations:  } &     4210    \\\\\n",
       "\\textbf{Model:}                  &      Logit       & \\textbf{  Df Residuals:      } &     4207    \\\\\n",
       "\\textbf{Method:}                 &       MLE        & \\textbf{  Df Model:          } &        2    \\\\\n",
       "\\textbf{Date:}                   & Fri, 15 Nov 2024 & \\textbf{  Pseudo R-squ.:     } &  0.001073   \\\\\n",
       "\\textbf{Time:}                   &     18:51:31     & \\textbf{  Log-Likelihood:    } &   -2911.4   \\\\\n",
       "\\textbf{converged:}              &       True       & \\textbf{  LL-Null:           } &   -2914.6   \\\\\n",
       "\\textbf{Covariance Type:}        &    nonrobust     & \\textbf{  LLR p-value:       } &  0.04387    \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                                 & \\textbf{coef} & \\textbf{std err} & \\textbf{z} & \\textbf{P$> |$z$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}               &       0.0073  &        0.096     &     0.076  &         0.940        &       -0.182    &        0.196     \\\\\n",
       "\\textbf{C(DEMO\\_student)[T.Yes]} &       0.1999  &        0.082     &     2.446  &         0.014        &        0.040    &        0.360     \\\\\n",
       "\\textbf{DEMO\\_age}               &       0.0009  &        0.002     &     0.405  &         0.685        &       -0.003    &        0.005     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{Logit Regression Results}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:          LONELY_direct   No. Observations:                 4210\n",
       "Model:                          Logit   Df Residuals:                     4207\n",
       "Method:                           MLE   Df Model:                            2\n",
       "Date:                Fri, 15 Nov 2024   Pseudo R-squ.:                0.001073\n",
       "Time:                        18:51:31   Log-Likelihood:                -2911.4\n",
       "converged:                       True   LL-Null:                       -2914.6\n",
       "Covariance Type:            nonrobust   LLR p-value:                   0.04387\n",
       "==========================================================================================\n",
       "                             coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------------\n",
       "Intercept                  0.0073      0.096      0.076      0.940      -0.182       0.196\n",
       "C(DEMO_student)[T.Yes]     0.1999      0.082      2.446      0.014       0.040       0.360\n",
       "DEMO_age                   0.0009      0.002      0.405      0.685      -0.003       0.005\n",
       "==========================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_model_additive_spec_alt = 'LONELY_direct ~ DEMO_age + C(DEMO_student)'\n",
    "linear_model_additive_spec_alt_fit = smf.logit(formula=linear_model_additive_spec_alt, data=cscs).fit()\n",
    "linear_model_additive_spec_alt_fit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# Define a range for DEMO_age\n",
    "age_range = np.linspace(cscs['DEMO_age'].min(), cscs['DEMO_age'].max(), 100)\n",
    "\n",
    "# Create a DataFrame for prediction\n",
    "predict_df = pd.DataFrame({\n",
    "    'DEMO_age': np.tile(age_range, 2),  # Repeat the age range for each student status\n",
    "    'DEMO_student': ['Yes'] * len(age_range) + ['No'] * len(age_range)\n",
    "})\n",
    "\n",
    "# Calculate predicted probabilities\n",
    "predict_df['predicted_prob'] = linear_model_additive_spec_alt_fit.predict(predict_df)\n",
    "\n",
    "# Create a line plot\n",
    "fig = px.line(\n",
    "    predict_df,\n",
    "    x='DEMO_age',\n",
    "    y='predicted_prob',\n",
    "    color='DEMO_student',\n",
    "    labels={'DEMO_age': 'Age', 'predicted_prob': 'Probability of Loneliness'},\n",
    "    title='Predicted Probability of Loneliness by Age and Student Status'\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show(renderer='png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe this is right?\n",
    "\n",
    "**I'm not sure if I'm going anything right is this question, if I'm doing bad just take it as I give up on this question, I have no idea what is going on dude.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok... That was even worse... Although it seems like the women group from the gender indicator variable shows some strong relationship with the outcome...\n",
    "\n",
    "Let's move on and try synergistic models.\n",
    "\n",
    "I first tried an interaction between age and gender, since, maybe gender effects how much age influences the feeling of lonliness, and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.687324\n",
      "         Iterations 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>LONELY_direct</td>  <th>  No. Observations:  </th>  <td>  4210</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td>  4204</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>     5</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Fri, 15 Nov 2024</td> <th>  Pseudo R-squ.:     </th> <td>0.007178</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>18:51:31</td>     <th>  Log-Likelihood:    </th> <td> -2893.6</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -2914.6</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>6.341e-08</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                    <td></td>                       <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                             <td>    0.0323</td> <td>    0.135</td> <td>    0.239</td> <td> 0.811</td> <td>   -0.232</td> <td>    0.297</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(DEMO_gender)[T.Non-binary]</th>          <td>    2.4016</td> <td>    0.676</td> <td>    3.550</td> <td> 0.000</td> <td>    1.076</td> <td>    3.727</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(DEMO_gender)[T.Woman]</th>               <td>    0.2303</td> <td>    0.178</td> <td>    1.297</td> <td> 0.195</td> <td>   -0.118</td> <td>    0.579</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>DEMO_age</th>                              <td>   -0.0037</td> <td>    0.004</td> <td>   -1.050</td> <td> 0.294</td> <td>   -0.011</td> <td>    0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>DEMO_age:C(DEMO_gender)[T.Non-binary]</th> <td>   -0.0611</td> <td>    0.019</td> <td>   -3.244</td> <td> 0.001</td> <td>   -0.098</td> <td>   -0.024</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>DEMO_age:C(DEMO_gender)[T.Woman]</th>      <td>    0.0026</td> <td>    0.004</td> <td>    0.588</td> <td> 0.557</td> <td>   -0.006</td> <td>    0.011</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}                          &  LONELY\\_direct  & \\textbf{  No. Observations:  } &     4210    \\\\\n",
       "\\textbf{Model:}                                  &      Logit       & \\textbf{  Df Residuals:      } &     4204    \\\\\n",
       "\\textbf{Method:}                                 &       MLE        & \\textbf{  Df Model:          } &        5    \\\\\n",
       "\\textbf{Date:}                                   & Fri, 15 Nov 2024 & \\textbf{  Pseudo R-squ.:     } &  0.007178   \\\\\n",
       "\\textbf{Time:}                                   &     18:51:31     & \\textbf{  Log-Likelihood:    } &   -2893.6   \\\\\n",
       "\\textbf{converged:}                              &       True       & \\textbf{  LL-Null:           } &   -2914.6   \\\\\n",
       "\\textbf{Covariance Type:}                        &    nonrobust     & \\textbf{  LLR p-value:       } & 6.341e-08   \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                                                 & \\textbf{coef} & \\textbf{std err} & \\textbf{z} & \\textbf{P$> |$z$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}                               &       0.0323  &        0.135     &     0.239  &         0.811        &       -0.232    &        0.297     \\\\\n",
       "\\textbf{C(DEMO\\_gender)[T.Non-binary]}           &       2.4016  &        0.676     &     3.550  &         0.000        &        1.076    &        3.727     \\\\\n",
       "\\textbf{C(DEMO\\_gender)[T.Woman]}                &       0.2303  &        0.178     &     1.297  &         0.195        &       -0.118    &        0.579     \\\\\n",
       "\\textbf{DEMO\\_age}                               &      -0.0037  &        0.004     &    -1.050  &         0.294        &       -0.011    &        0.003     \\\\\n",
       "\\textbf{DEMO\\_age:C(DEMO\\_gender)[T.Non-binary]} &      -0.0611  &        0.019     &    -3.244  &         0.001        &       -0.098    &       -0.024     \\\\\n",
       "\\textbf{DEMO\\_age:C(DEMO\\_gender)[T.Woman]}      &       0.0026  &        0.004     &     0.588  &         0.557        &       -0.006    &        0.011     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{Logit Regression Results}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:          LONELY_direct   No. Observations:                 4210\n",
       "Model:                          Logit   Df Residuals:                     4204\n",
       "Method:                           MLE   Df Model:                            5\n",
       "Date:                Fri, 15 Nov 2024   Pseudo R-squ.:                0.007178\n",
       "Time:                        18:51:31   Log-Likelihood:                -2893.6\n",
       "converged:                       True   LL-Null:                       -2914.6\n",
       "Covariance Type:            nonrobust   LLR p-value:                 6.341e-08\n",
       "=========================================================================================================\n",
       "                                            coef    std err          z      P>|z|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------------------------------\n",
       "Intercept                                 0.0323      0.135      0.239      0.811      -0.232       0.297\n",
       "C(DEMO_gender)[T.Non-binary]              2.4016      0.676      3.550      0.000       1.076       3.727\n",
       "C(DEMO_gender)[T.Woman]                   0.2303      0.178      1.297      0.195      -0.118       0.579\n",
       "DEMO_age                                 -0.0037      0.004     -1.050      0.294      -0.011       0.003\n",
       "DEMO_age:C(DEMO_gender)[T.Non-binary]    -0.0611      0.019     -3.244      0.001      -0.098      -0.024\n",
       "DEMO_age:C(DEMO_gender)[T.Woman]          0.0026      0.004      0.588      0.557      -0.006       0.011\n",
       "=========================================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now do synergistic model\n",
    "linear_model_synergistic_spec = 'LONELY_direct ~ DEMO_age * C(DEMO_gender)'\n",
    "log_reg_fit = smf.logit(formula=linear_model_synergistic_spec, data=cscs).fit()\n",
    "log_reg_fit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like not.\n",
    "\n",
    "*Also I don't have the slightest idea how to plot this, I've tried asking ChatGPT and it just doesn't help*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "\n",
    "To explain this seemingly contradictory phenomenon of having very low p-value for many of the coefficients in an MLR model, but also having a low R-squared value, we need to first revisit and understand what each of them are really representing.\n",
    "\n",
    "We've explored before from HW06 last week that the R-squared value for a fitted regression model measures how accurately the model represents the real relationship between $X$ and $Y$, and it specifically refers to the proportion of variation in $Y$ that is explained by the variation in $X$. Note that **the R-squared value measures the accuracy of the model as a whole**, looking at how well the model predicts the outcome variable based on predictor variable input.\n",
    "\n",
    "We've also briefly talked about how we interpret the fitted results from a regression model specification, how a lower p-value for a specific coefficient means that this predictor variable is likely to have an effect on the outcome variable. We know this, because a low p-value provides evidence against a null hypothesis, in the context of linear regression, the null hypothesis is that the predictor variable has no effect on the outcome variable. Therefore, the low p-value shows evidence against this. \n",
    "\n",
    "Now, note how **the p-value only looks at whether or not a specific variable is related (or has an effect on) the outcome variable**, and not the entire model as a whole or any other variables. In other words, **a low p-value from a specific predictor variable does not imply that it explains a substantial portion of the variability in the outcome variable.**\n",
    "\n",
    "Furthermore, although having a low p-value may suggest significant relationship, it's real siginificance in the model as a whole may not be as prominent. This can most likely be explained looking at the coefficients for the predictor variables. If the magnitude of the coefficients for the predictor variable is low, although having a significant relationship with the outcome, the overall significance of this variable in the model is low, since any variations in this predictor will end up with very little variations in the outcome in the end. **Therefore, those predictors who have a low/insignificant coefficient might not account for the accuracy of the model overall.**\n",
    "\n",
    "Looking at the given example, we see that many of the \"Sp. Def\" predictor variables have a relatively insignificant coefficient, many of which are less than 1. This means that these predictors do not contribute as much to the model as a whole, and therefore their low p-values do not speak much for the accuracy of the model.\n",
    "\n",
    "Going back a little, the model specification itself also might cause this type of phenomenon. With an existing specification, if we see that many of our predictors have a low p-value yet the R-squared for the model is low, we might be missing something in our specification, that is actually needed to be included in the consideration of the model for the model to fit the data better. **In other words, there may be other factors that contribute to the variability in $Y$ that is not included in the current model specification.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/KeithGalli/pandas/master/pokemon_data.csv\"\n",
    "# fail https://github.com/KeithGalli/pandas/blob/master/pokemon_data.csv\n",
    "pokeaman = pd.read_csv(url) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "\n",
    "These five cells of code are mainly illustrating the concept of **Overfitting**, which is when we try to create a model that overly captures the characteristics of the training data and fails to generalize the relationship between the predictor and outcome variables. **Overfitting** is commonly caused by an overly complex model, that essentially tries to \"memorize\" the training data instead of modelling or generalizing it. As a result, when we try to use the model to explain the variation of the outcomes in the testing data, we get a incredibly low result.\n",
    "\n",
    "The first code block uses the `train_test_split` method from `sklearn.model_selection` to create a testing and training dataset. The `pokeaman_train` part will be used to fit the MLR model specification, and the `pokeaman_test` part will be used to test the fitted model.\n",
    "\n",
    "Then, a MLR model specification is created a fitted, with the predictor variables being `Attack` and `Defense` and the outcome variable being `HP`. This MLR model specification solely looks at the two predictors additively, meaning that one predictor's influence on `HP` is not affected by the other predictor, so there is no interaction between the two.\n",
    "\n",
    "The linear form of this specification is:\n",
    "\n",
    "$$Y=\\beta_0 + \\beta_1 \\cdot \\text{Attack} + \\beta_2 \\cdot \\text{Defense} + \\epsilon$$\n",
    "\n",
    "In the results, we indeed see that both `Attack` and `Defense` have a significant relationship with `HP`, however our model does not explain much of the variability in `HP`, with a R-squared value of only 0.148. Note that this R-squared value is calculated by calculating the squared correlation coefficient between the predicted values for `HP` from the model and the values of `HP` from the observation (the `pokeaman_train` dataset).\n",
    "\n",
    "To look at whether or not this model really represents the relationship between the outcome and predicator variables, we can take a testing dataset and see the R-squared value for it, and this is exactly what the `pokeaman_test` data is for. As a result, surprisingly, we see a similar yet better resulting R-squared of around 0.212.\n",
    "\n",
    "But our R-squared value is still quite low, it doesn't represent the relationship well enough, so we can make some changes to our specification so that it can better predict the outcomes. In the next code block, we create a new MLR model specification that is much more complex, with interactions between `Attack`, `Defense`, `Speed`, and `Legendary`, plus interactions between `Sp. Def` and `Sp. Atk`. This ends up with a really complex linear form that includes all possible combinations between the four interacting predictors and the two `Sp.` interacting predictors that is probably too much to type here in the notebook...\n",
    "\n",
    "After fitting this MLR model, we end up with a R-squared of 0.467, which is much higher than before. But don't forget that this is tested on the provided dataset, to see if the model really predicts the outcome well, we need to use the testing dataset to test the model. As a result, we end up with a `Out of sample R-squared` of only 0.002.\n",
    "\n",
    "As we've explained before, this is one of the indicators of a severely overfitted regression model, where the fitted model fails to generalize the relationship between outcome and predicator values, frequently trying to capture those very intricate characteristics from the training dataset, causing it fail to predict values from the testing dataset. Overfitting generally happens when the the model specification is overly complex relative to the available data used to fit the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>Name</th>\n",
       "      <th>Type 1</th>\n",
       "      <th>Type 2</th>\n",
       "      <th>HP</th>\n",
       "      <th>Attack</th>\n",
       "      <th>Defense</th>\n",
       "      <th>Sp. Atk</th>\n",
       "      <th>Sp. Def</th>\n",
       "      <th>Speed</th>\n",
       "      <th>Generation</th>\n",
       "      <th>Legendary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>338</td>\n",
       "      <td>Solrock</td>\n",
       "      <td>Rock</td>\n",
       "      <td>Psychic</td>\n",
       "      <td>70</td>\n",
       "      <td>95</td>\n",
       "      <td>85</td>\n",
       "      <td>55</td>\n",
       "      <td>65</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Charizard</td>\n",
       "      <td>Fire</td>\n",
       "      <td>Flying</td>\n",
       "      <td>78</td>\n",
       "      <td>84</td>\n",
       "      <td>78</td>\n",
       "      <td>109</td>\n",
       "      <td>85</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>224</td>\n",
       "      <td>Octillery</td>\n",
       "      <td>Water</td>\n",
       "      <td>None</td>\n",
       "      <td>75</td>\n",
       "      <td>105</td>\n",
       "      <td>75</td>\n",
       "      <td>105</td>\n",
       "      <td>75</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>600</td>\n",
       "      <td>Klang</td>\n",
       "      <td>Steel</td>\n",
       "      <td>None</td>\n",
       "      <td>60</td>\n",
       "      <td>80</td>\n",
       "      <td>95</td>\n",
       "      <td>70</td>\n",
       "      <td>85</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>265</td>\n",
       "      <td>Wurmple</td>\n",
       "      <td>Bug</td>\n",
       "      <td>None</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>35</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>471</td>\n",
       "      <td>Glaceon</td>\n",
       "      <td>Ice</td>\n",
       "      <td>None</td>\n",
       "      <td>65</td>\n",
       "      <td>60</td>\n",
       "      <td>110</td>\n",
       "      <td>130</td>\n",
       "      <td>95</td>\n",
       "      <td>65</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>225</td>\n",
       "      <td>Delibird</td>\n",
       "      <td>Ice</td>\n",
       "      <td>Flying</td>\n",
       "      <td>45</td>\n",
       "      <td>55</td>\n",
       "      <td>45</td>\n",
       "      <td>65</td>\n",
       "      <td>45</td>\n",
       "      <td>75</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>720</td>\n",
       "      <td>HoopaHoopa Confined</td>\n",
       "      <td>Psychic</td>\n",
       "      <td>Ghost</td>\n",
       "      <td>80</td>\n",
       "      <td>110</td>\n",
       "      <td>60</td>\n",
       "      <td>150</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>109</td>\n",
       "      <td>Koffing</td>\n",
       "      <td>Poison</td>\n",
       "      <td>None</td>\n",
       "      <td>40</td>\n",
       "      <td>65</td>\n",
       "      <td>95</td>\n",
       "      <td>60</td>\n",
       "      <td>45</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>373</td>\n",
       "      <td>SalamenceMega Salamence</td>\n",
       "      <td>Dragon</td>\n",
       "      <td>Flying</td>\n",
       "      <td>95</td>\n",
       "      <td>145</td>\n",
       "      <td>130</td>\n",
       "      <td>120</td>\n",
       "      <td>90</td>\n",
       "      <td>120</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows  12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       #                     Name   Type 1   Type 2  HP  Attack  Defense  \\\n",
       "370  338                  Solrock     Rock  Psychic  70      95       85   \n",
       "6      6                Charizard     Fire   Flying  78      84       78   \n",
       "242  224                Octillery    Water     None  75     105       75   \n",
       "661  600                    Klang    Steel     None  60      80       95   \n",
       "288  265                  Wurmple      Bug     None  45      45       35   \n",
       "..   ...                      ...      ...      ...  ..     ...      ...   \n",
       "522  471                  Glaceon      Ice     None  65      60      110   \n",
       "243  225                 Delibird      Ice   Flying  45      55       45   \n",
       "797  720      HoopaHoopa Confined  Psychic    Ghost  80     110       60   \n",
       "117  109                  Koffing   Poison     None  40      65       95   \n",
       "409  373  SalamenceMega Salamence   Dragon   Flying  95     145      130   \n",
       "\n",
       "     Sp. Atk  Sp. Def  Speed  Generation  Legendary  \n",
       "370       55       65     70           3      False  \n",
       "6        109       85    100           1      False  \n",
       "242      105       75     45           2      False  \n",
       "661       70       85     50           5      False  \n",
       "288       20       30     20           3      False  \n",
       "..       ...      ...    ...         ...        ...  \n",
       "522      130       95     65           4      False  \n",
       "243       65       45     75           2      False  \n",
       "797      150      130     70           6       True  \n",
       "117       60       45     35           1      False  \n",
       "409      120       90    120           3      False  \n",
       "\n",
       "[400 rows x 12 columns]"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fifty_fifty_split_size = int(pokeaman.shape[0]*0.5)\n",
    "\n",
    "# Replace \"NaN\" (in the \"Type 2\" column with \"None\")\n",
    "pokeaman.fillna('None', inplace=True)\n",
    "\n",
    "np.random.seed(130)\n",
    "pokeaman_train,pokeaman_test = \\\n",
    "  train_test_split(pokeaman, train_size=fifty_fifty_split_size)\n",
    "pokeaman_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "\n",
    "We've explored how an overly complex MLR model specification can lead to overfitting when the complexity relatively exceeds the available data. As a result, although the model fits the fitted data well, when we use a new piece of data to test the model, it fails to accurately predict the outcomes. We learn that by using a in-sample and out-of-sample test to find the R-squared value, we can see whether or not overfitting has occured, as observed by a great drop in the R-squared value.\n",
    "\n",
    "Now, is there a way we could identify these possible overfittings without having such a comparison between in-sample and out-sample tests. The ultimate goal of such regression models is being able to accurately predict the outcome variables while maintaining good generalizability, meaning that the model is able to generally give good predictions to any given data.\n",
    "\n",
    "One thing that affects the generalizability of model fits is multicollinearity, it is when two or more predictor variables in the model are highly correlated to each other. When predictors are correlated, the regression algorithm will struggle to identify unique contributions each predicator makes to the outcome, as they carry redundant information. This causes the coefficients for these predictor variables to be highly unstable, and therefore fail to generalize as these coefficients are reflecting the noise in the data and the redundancy of the predictors, and not the true relationships between the predictors and the outcomes.\n",
    "\n",
    "One way to measure the multicollinearity that is present in a model fit is the **condition number** of a **design matrix** of the model specification. The design matrix is a matrix representation of the predictor variables in a regression model, where the rows represent the observations (or data points) and the columns represent the predictors (including any transformations and/or interactions). The representation of a regression model specification in this format simplifies the computation for both fitting the model, and doing diagnostics such as calculating our **condition number**.\n",
    "\n",
    "Now, like we've said, the condition number is a measure of multicollinearity present in a model fit, where a very large condition number suggests a large degree of multicollinearity, and therefore suggests that the fitted model is overfitted and questions the generalizability of the model.\n",
    "\n",
    "We can actually see this happening from the preivous example in `model4`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>214.307</td> <th>  Durbin-Watson:     </th> <td>   1.992</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2354.664</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.026</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>14.174</td>  <th>  Cond. No.          </th> <td>1.20e+16</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Omnibus:}       & 214.307 & \\textbf{  Durbin-Watson:     } &    1.992  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 2354.664  \\\\\n",
       "\\textbf{Skew:}          &   2.026 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  14.174 & \\textbf{  Cond. No.          } & 1.20e+16  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4_linear_form = 'HP ~ Attack * Defense * Speed * Legendary'\n",
    "model4_linear_form += ' * Q(\"Sp. Def\") * Q(\"Sp. Atk\")'\n",
    "# DO NOT try adding '* C(Generation) * C(Q(\"Type 1\")) * C(Q(\"Type 2\"))'\n",
    "# That's 6*18*19 = 6*18*19 possible interaction combinations...\n",
    "# ...a huge number that will blow up your computer\n",
    "\n",
    "model4_spec = smf.ols(formula=model4_linear_form, data=pokeaman_train)\n",
    "model4_fit = model4_spec.fit()\n",
    "model4_fit.summary().tables[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A condition number of 12 and then 15 zeros, this is a very large condition number! Therefore suggesting that this model has high multicollinearity, and thus we see the bad generalizability when testing the model with the testing dataset.\n",
    "\n",
    "The condition number can be lowered by using centering, which subtracts the mean of each predictor, making the mean of the predictor variable 0, as well as scaling, by dividing each predictor by its standard deviation, making the variance in the variable 1. Centering ans scaling are useful in reducing multicollinearity caused by interaction terms or predictors with large absolute values. Scaling is especially important for interaction terms as the multiplicated may cause the variables to not be on the same scale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 7\n",
    "\n",
    "In this first improved version of the MLR model specification based on `model3`, we can see that in `model5`, it maintains the simplicity of `model3` in a sense that there are not many interactions leading to high complexity, and predictor relationships are purely additive. Like we've previously addressed, when the complexity of the model specification (relatively) exceeds the amount of data in the dataset, overfitting is likely to occur. What makes `model5` different from `model3` however is that `model5` presents adds on more predictors, like in `model4`, including `speed`, `Sp. Def`, and `Sp. Atk`, as well as categorical variable predictors, including `Generation`, `Type 1` and `Type 2`, These categorical variables will be automatically expanded into dummy variables.\n",
    "\n",
    "Although a lot more predictors have been added to the specification, like we've just said, there are not interactions that lead to high complexity, and therefore the model is kept simple, maintaining generalizability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>286.476</td> <th>  Durbin-Watson:     </th> <td>   1.917</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>5187.327</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.807</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>19.725</td>  <th>  Cond. No.          </th> <td>9.21e+03</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Omnibus:}       & 286.476 & \\textbf{  Durbin-Watson:     } &    1.917  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 5187.327  \\\\\n",
       "\\textbf{Skew:}          &   2.807 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  19.725 & \\textbf{  Cond. No.          } & 9.21e+03  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here's something a little more reasonable...\n",
    "model5_linear_form = 'HP ~ Attack + Defense + Speed + Legendary'\n",
    "model5_linear_form += ' + Q(\"Sp. Def\") + Q(\"Sp. Atk\")'\n",
    "model5_linear_form += ' + C(Generation) + C(Q(\"Type 1\")) + C(Q(\"Type 2\"))'\n",
    "\n",
    "model5_spec = smf.ols(formula=model5_linear_form, data=pokeaman_train)\n",
    "model5_fit = model5_spec.fit()\n",
    "model5_fit.summary().tables[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following improved version of the MLR model specification is based on `model5`, and also includes a number of changes that make the model have better generalizability. For example, in the base formula, the main continuous predictors now only include `Attack`, `Speed`, `Sp. Def`, and `Sp. Atk` ad additive predictors. `Defense` and `Legendary` were excluded as they may have contributed to complex interaction terms and multicollinearity.\n",
    "\n",
    "Furthermore, `model6` has added binary indicator variables, such as `I(Q(\"Type 1\")==\"Normal\")`, `I(Q(\"Type 1\")==\"Water\")`, `I(Generation==2)`, `I(Generation==5)`. By using binary indicator variables, we are looking at specific indicators and groups that most likely are relevant to variability in the outcome variable, and focusing on them to improve interpretability and generalizability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>271.290</td> <th>  Durbin-Watson:     </th> <td>   1.999</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>4238.692</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.651</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>18.040</td>  <th>  Cond. No.          </th> <td>    618.</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Omnibus:}       & 271.290 & \\textbf{  Durbin-Watson:     } &    1.999  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 4238.692  \\\\\n",
       "\\textbf{Skew:}          &   2.651 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  18.040 & \\textbf{  Cond. No.          } &     618.  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here's something a little more reasonable...\n",
    "model6_linear_form = 'HP ~ Attack + Speed + Q(\"Sp. Def\") + Q(\"Sp. Atk\")'\n",
    "# And here we'll add the significant indicators from the previous model\n",
    "# https://chatgpt.com/share/81ab88df-4f07-49f9-a44a-de0cfd89c67c\n",
    "model6_linear_form += ' + I(Q(\"Type 1\")==\"Normal\")'\n",
    "model6_linear_form += ' + I(Q(\"Type 1\")==\"Water\")'\n",
    "model6_linear_form += ' + I(Generation==2)'\n",
    "model6_linear_form += ' + I(Generation==5)'\n",
    "\n",
    "model6_spec = smf.ols(formula=model6_linear_form, data=pokeaman_train)\n",
    "model6_fit = model6_spec.fit()\n",
    "model6_fit.summary().tables[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we have `model7` that is based on `model6`, which its main difference is introducing interactions between variables. Contrary to the specifications earlier that also introduced interactions, which actually caused lots of unncessary complexity leading to overfitting, `model7` focuses interactions onto specific, continuous predictors: `Attack`, `Speed`, `Sp. Def`, `Sp. Atk`, that are likely to have some natural relationship between one another.\n",
    "\n",
    "The earlier models (such as `model4`) lead to overfitting with the introduction of interactions because the interacting variables were introduced without regard to their relevance, often mixing continuous and categorical predictors, or including very high-order terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>252.300</td> <th>  Durbin-Watson:     </th> <td>   1.953</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>3474.611</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.438</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>16.590</td>  <th>  Cond. No.          </th> <td>2.34e+09</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Omnibus:}       & 252.300 & \\textbf{  Durbin-Watson:     } &    1.953  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 3474.611  \\\\\n",
       "\\textbf{Skew:}          &   2.438 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  16.590 & \\textbf{  Cond. No.          } & 2.34e+09  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And here's a slight change that seems to perhaps improve prediction...\n",
    "model7_linear_form = 'HP ~ Attack * Speed * Q(\"Sp. Def\") * Q(\"Sp. Atk\")'\n",
    "model7_linear_form += ' + I(Q(\"Type 1\")==\"Normal\")'\n",
    "model7_linear_form += ' + I(Q(\"Type 1\")==\"Water\")'\n",
    "model7_linear_form += ' + I(Generation==2)'\n",
    "model7_linear_form += ' + I(Generation==5)'\n",
    "\n",
    "model7_spec = smf.ols(formula=model7_linear_form, data=pokeaman_train)\n",
    "model7_fit = model7_spec.fit()\n",
    "model7_fit.summary().tables[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We still have a very large condition number though, we can do some centering and scaling to reduce the multicollinearity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>252.300</td> <th>  Durbin-Watson:     </th> <td>   1.953</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>3474.611</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.438</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>16.590</td>  <th>  Cond. No.          </th> <td>    15.4</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Omnibus:}       & 252.300 & \\textbf{  Durbin-Watson:     } &    1.953  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 3474.611  \\\\\n",
       "\\textbf{Skew:}          &   2.438 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  16.590 & \\textbf{  Cond. No.          } &     15.4  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And here's a slight change that seems to perhas improve prediction...\n",
    "model7_linear_form_CS = 'HP ~ scale(center(Attack)) * scale(center(Speed))'\n",
    "model7_linear_form_CS += ' * scale(center(Q(\"Sp. Def\"))) * scale(center(Q(\"Sp. Atk\")))'\n",
    "# We DO NOT center and scale indicator variables\n",
    "model7_linear_form_CS += ' + I(Q(\"Type 1\")==\"Normal\")'\n",
    "model7_linear_form_CS += ' + I(Q(\"Type 1\")==\"Water\")'\n",
    "model7_linear_form_CS += ' + I(Generation==2)'\n",
    "model7_linear_form_CS += ' + I(Generation==5)'\n",
    "\n",
    "model7_CS_spec = smf.ols(formula=model7_linear_form_CS, data=pokeaman_train)\n",
    "model7_CS_fit = model7_CS_spec.fit()\n",
    "model7_CS_fit.summary().tables[-1] \n",
    "# \"Cond. No.\" is NOW 15.4 due to centering and scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now our condition number is only 15.4, which suggests small problems related to multicollinearity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "customdata": [
          [
           1
          ],
          [
           2
          ],
          [
           3
          ],
          [
           4
          ],
          [
           5
          ],
          [
           6
          ],
          [
           7
          ],
          [
           8
          ],
          [
           9
          ],
          [
           10
          ],
          [
           11
          ],
          [
           12
          ],
          [
           13
          ],
          [
           14
          ],
          [
           15
          ],
          [
           16
          ],
          [
           17
          ],
          [
           18
          ],
          [
           19
          ],
          [
           20
          ],
          [
           21
          ],
          [
           22
          ],
          [
           23
          ],
          [
           24
          ],
          [
           25
          ],
          [
           26
          ],
          [
           27
          ],
          [
           28
          ],
          [
           29
          ],
          [
           30
          ],
          [
           31
          ],
          [
           32
          ],
          [
           33
          ],
          [
           34
          ],
          [
           35
          ],
          [
           36
          ],
          [
           37
          ],
          [
           38
          ],
          [
           39
          ],
          [
           40
          ],
          [
           41
          ],
          [
           42
          ],
          [
           43
          ],
          [
           44
          ],
          [
           45
          ],
          [
           46
          ],
          [
           47
          ],
          [
           48
          ],
          [
           49
          ],
          [
           50
          ],
          [
           51
          ],
          [
           52
          ],
          [
           53
          ],
          [
           54
          ],
          [
           55
          ],
          [
           56
          ],
          [
           57
          ],
          [
           58
          ],
          [
           59
          ],
          [
           60
          ],
          [
           61
          ],
          [
           62
          ],
          [
           63
          ],
          [
           64
          ],
          [
           65
          ],
          [
           66
          ],
          [
           67
          ],
          [
           68
          ],
          [
           69
          ],
          [
           70
          ],
          [
           71
          ],
          [
           72
          ],
          [
           73
          ],
          [
           74
          ],
          [
           75
          ],
          [
           76
          ],
          [
           77
          ],
          [
           78
          ],
          [
           79
          ],
          [
           80
          ],
          [
           81
          ],
          [
           82
          ],
          [
           83
          ],
          [
           84
          ],
          [
           85
          ],
          [
           86
          ],
          [
           87
          ],
          [
           88
          ],
          [
           89
          ],
          [
           90
          ],
          [
           91
          ],
          [
           92
          ],
          [
           93
          ],
          [
           94
          ],
          [
           95
          ],
          [
           96
          ],
          [
           97
          ],
          [
           98
          ],
          [
           99
          ],
          [
           100
          ]
         ],
         "hovertemplate": "In-Sample R-squared=%{x}<br>Out-of-Sample R-squared=%{y}<br>Repetition=%{customdata[0]}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": "#636efa",
          "size": 8,
          "symbol": "circle"
         },
         "mode": "markers+text",
         "name": "",
         "orientation": "v",
         "showlegend": false,
         "text": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100
         ],
         "type": "scatter",
         "x": [
          0.31337130987271866,
          0.3105484030761002,
          0.31670210718926284,
          0.3025476045887048,
          0.4129368612094838,
          0.3545120744835595,
          0.3259215517412771,
          0.374058064965641,
          0.3011689298166411,
          0.41248555997507386,
          0.29536329148221696,
          0.41836998446542784,
          0.3101063375608113,
          0.36936902817426687,
          0.3352623455327195,
          0.27216229997786845,
          0.40818222729832154,
          0.35430110421033156,
          0.3292294487669346,
          0.3374278411108964,
          0.30480135663551744,
          0.3677718679181561,
          0.34334189093919143,
          0.34652359612430106,
          0.4156701757124136,
          0.3143401915438646,
          0.38893691944049114,
          0.33709212647830955,
          0.3301422805306343,
          0.3235305338137663,
          0.3399819131321137,
          0.38940995297713976,
          0.37630323383568154,
          0.2902806577821583,
          0.2544092457299858,
          0.34067740830629367,
          0.35237583220803903,
          0.34814698719997206,
          0.34432204933418153,
          0.339308020348575,
          0.2982001174865292,
          0.31246261835019673,
          0.40262100553970004,
          0.28068295032621227,
          0.40829623047768315,
          0.3115173408514097,
          0.3248072613169297,
          0.39492515379259807,
          0.3474877313737732,
          0.324855205126966,
          0.3221198049762366,
          0.34854876302486704,
          0.3116900087029003,
          0.4299338916328934,
          0.34623273201219273,
          0.32526109641357137,
          0.4015145291422344,
          0.3230759361095312,
          0.33649270312951174,
          0.36250242448989467,
          0.321812658948315,
          0.38710864422336866,
          0.4131366573346378,
          0.2887676472450772,
          0.30758813408497887,
          0.3419868236241099,
          0.45281138435336665,
          0.33280084628047046,
          0.2710356641933608,
          0.3198306007496383,
          0.26646162334762336,
          0.3269280810162456,
          0.2919615695124629,
          0.3539321321119676,
          0.3563746644966991,
          0.33012701775815545,
          0.3822590652109631,
          0.36862706813880197,
          0.2862970079491033,
          0.38740285430094157,
          0.353960582441221,
          0.38302074235658656,
          0.33645539687280845,
          0.3772580036902873,
          0.345466998195763,
          0.3643605669496167,
          0.2987690167304985,
          0.31825963868722873,
          0.29131558101186183,
          0.2714093878248435,
          0.3278619119714916,
          0.31442703916171755,
          0.38101151403648104,
          0.3573881926842143,
          0.3129589508083437,
          0.2559498472926024,
          0.3471875413358836,
          0.28384476445722406,
          0.34344615421678404,
          0.2805688809276101
         ],
         "xaxis": "x",
         "y": [
          0.3265024256199826,
          0.3288449838085553,
          0.3323290089215285,
          0.3493688603538705,
          0.24814802691476115,
          0.2986696776444166,
          0.31494877728873505,
          0.25870236623560994,
          0.3431504711424928,
          0.24808795184987092,
          0.35216997368478914,
          0.24411906075840611,
          0.2973519247914259,
          0.26816155719554396,
          0.29926904657683745,
          0.4071801640773773,
          0.24823648961529593,
          0.2930949531217247,
          0.3155565954870462,
          0.3083707214107835,
          0.3361305767122505,
          0.2680532866365924,
          0.29680821505617955,
          0.3055511712387624,
          0.2344075796313171,
          0.29978755196579643,
          0.2577997687514741,
          0.29430698344669143,
          0.29710565257080673,
          0.32905297849899456,
          0.316227371300133,
          0.2445927742300484,
          0.26760111492515126,
          0.3568334829922592,
          0.3927652317782972,
          0.2937303922078782,
          0.2924448764649359,
          0.28761067542428476,
          0.2989191508851608,
          0.2858462067465361,
          0.33490400301412787,
          0.330121393043645,
          0.2516364150977379,
          0.3622045062705153,
          0.25679990280540127,
          0.3118571561257325,
          0.311669786874063,
          0.24768062217529702,
          0.28877226487869856,
          0.3128012639559136,
          0.3066227237687702,
          0.28852001661917825,
          0.31619648144189416,
          0.227400069268642,
          0.28697733987142354,
          0.29608904770444594,
          0.2702977266319498,
          0.330661640454581,
          0.3151357238339524,
          0.2775289212546262,
          0.3211123269773532,
          0.2588300089754916,
          0.2589114593086461,
          0.3548717280673653,
          0.31401194095389545,
          0.30404088074457997,
          0.23340035609677479,
          0.2997160890432434,
          0.37860132223931237,
          0.3255066095428727,
          0.3724837744081176,
          0.3080129396357201,
          0.355205864962926,
          0.28537532843277946,
          0.2899747167078266,
          0.3079454168738724,
          0.2653318723656054,
          0.28445265276809933,
          0.3738260482894332,
          0.25520488188321744,
          0.2881603802173969,
          0.2508724305551004,
          0.30239697931439896,
          0.22752267095260748,
          0.2569064948684551,
          0.2853590498142008,
          0.35110525470944165,
          0.3140680685477201,
          0.3618957631140536,
          0.3772551807003996,
          0.32017304574456024,
          0.3354275690411591,
          0.27283355368791057,
          0.2911827875902534,
          0.3291598984896466,
          0.39746886121320457,
          0.29467203881265147,
          0.3503463055548417,
          0.3041755841671857,
          0.3683319881657599
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "tracegroupgap": 0
        },
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "In-Sample vs. Out-of-Sample R-squared for Model6"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "In-Sample R-squared"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Out-Sample R-squared"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "model4_linear_form = 'HP ~ Attack * Defense * Speed * Legendary'\n",
    "model4_linear_form += ' * Q(\"Sp. Def\") * Q(\"Sp. Atk\")'\n",
    "\n",
    "# Define parameters for the single model\n",
    "model_name = \"Model6\"  # Example model name\n",
    "formula = model6_linear_form  # Define the model formula\n",
    "data = pokeaman  # The full dataset\n",
    "\n",
    "# Number of repetitions\n",
    "num_repetitions = 100\n",
    "\n",
    "# Initialize list to store performance metrics\n",
    "performance_metrics = []\n",
    "\n",
    "# Repeat the process for the model\n",
    "for _ in range(num_repetitions):\n",
    "    # Randomly split the data into 50% train and 50% test\n",
    "    train_data, test_data = train_test_split(data, train_size=0.5)\n",
    "\n",
    "    # Fit the model on the training data\n",
    "    model_spec = smf.ols(formula=formula, data=train_data)\n",
    "    model_fit = model_spec.fit()\n",
    "\n",
    "    # Calculate in-sample R-squared\n",
    "    in_sample_r2 = model_fit.rsquared\n",
    "\n",
    "    # Predict on test data\n",
    "    y_test = test_data.HP\n",
    "    yhat_test = model_fit.predict(test_data)\n",
    "\n",
    "    # Calculate out-of-sample R-squared\n",
    "    if len(y_test) > 1:  # Ensure there is enough data for correlation calculation\n",
    "        out_sample_r2 = np.corrcoef(y_test, yhat_test)[0, 1] ** 2\n",
    "    else:\n",
    "        out_sample_r2 = np.nan  # Handle cases with insufficient test data\n",
    "\n",
    "    # Store the results\n",
    "    performance_metrics.append({\n",
    "        \"Repetition\": _ + 1,\n",
    "        \"In-Sample R2\": in_sample_r2,\n",
    "        \"Out-Sample R2\": out_sample_r2,\n",
    "    })\n",
    "\n",
    "# Convert metrics to a DataFrame\n",
    "performance_df = pd.DataFrame(performance_metrics)\n",
    "\n",
    "# Plot the scatter plot using Plotly\n",
    "fig = px.scatter(\n",
    "    performance_df,\n",
    "    x=\"In-Sample R2\",\n",
    "    y=\"Out-Sample R2\",\n",
    "    title=f\"In-Sample vs Out-of-Sample R-squared ({model_name})\",\n",
    "    labels={\"In-Sample R2\": \"In-Sample R-squared\", \"Out-Sample R2\": \"Out-of-Sample R-squared\"},\n",
    "    text=\"Repetition\",\n",
    "    hover_data=[\"Repetition\"]\n",
    ")\n",
    "\n",
    "# Customize layout\n",
    "fig.update_traces(marker=dict(size=8))\n",
    "fig.update_layout(\n",
    "    title=f\"In-Sample vs. Out-of-Sample R-squared for {model_name}\",\n",
    "    xaxis=dict(title=\"In-Sample R-squared\"),\n",
    "    yaxis=dict(title=\"Out-Sample R-squared\"),\n",
    "    showlegend=False\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**That looks like a very strong negative relationship!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "customdata": [
          [
           1
          ],
          [
           2
          ],
          [
           3
          ],
          [
           4
          ],
          [
           5
          ],
          [
           6
          ],
          [
           7
          ],
          [
           8
          ],
          [
           9
          ],
          [
           10
          ],
          [
           11
          ],
          [
           12
          ],
          [
           13
          ],
          [
           14
          ],
          [
           15
          ],
          [
           16
          ],
          [
           17
          ],
          [
           18
          ],
          [
           19
          ],
          [
           20
          ],
          [
           21
          ],
          [
           22
          ],
          [
           23
          ],
          [
           24
          ],
          [
           25
          ],
          [
           26
          ],
          [
           27
          ],
          [
           28
          ],
          [
           29
          ],
          [
           30
          ],
          [
           31
          ],
          [
           32
          ],
          [
           33
          ],
          [
           34
          ],
          [
           35
          ],
          [
           36
          ],
          [
           37
          ],
          [
           38
          ],
          [
           39
          ],
          [
           40
          ],
          [
           41
          ],
          [
           42
          ],
          [
           43
          ],
          [
           44
          ],
          [
           45
          ],
          [
           46
          ],
          [
           47
          ],
          [
           48
          ],
          [
           49
          ],
          [
           50
          ],
          [
           51
          ],
          [
           52
          ],
          [
           53
          ],
          [
           54
          ],
          [
           55
          ],
          [
           56
          ],
          [
           57
          ],
          [
           58
          ],
          [
           59
          ],
          [
           60
          ],
          [
           61
          ],
          [
           62
          ],
          [
           63
          ],
          [
           64
          ],
          [
           65
          ],
          [
           66
          ],
          [
           67
          ],
          [
           68
          ],
          [
           69
          ],
          [
           70
          ],
          [
           71
          ],
          [
           72
          ],
          [
           73
          ],
          [
           74
          ],
          [
           75
          ],
          [
           76
          ],
          [
           77
          ],
          [
           78
          ],
          [
           79
          ],
          [
           80
          ],
          [
           81
          ],
          [
           82
          ],
          [
           83
          ],
          [
           84
          ],
          [
           85
          ],
          [
           86
          ],
          [
           87
          ],
          [
           88
          ],
          [
           89
          ],
          [
           90
          ],
          [
           91
          ],
          [
           92
          ],
          [
           93
          ],
          [
           94
          ],
          [
           95
          ],
          [
           96
          ],
          [
           97
          ],
          [
           98
          ],
          [
           99
          ],
          [
           100
          ]
         ],
         "hovertemplate": "In-Sample R-squared=%{x}<br>Out-of-Sample R-squared=%{y}<br>Repetition=%{customdata[0]}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": "#636efa",
          "size": 8,
          "symbol": "circle"
         },
         "mode": "markers+text",
         "name": "",
         "orientation": "v",
         "showlegend": false,
         "text": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100
         ],
         "type": "scatter",
         "x": [
          0.5391298129262923,
          0.5364013040071678,
          0.4832522233663509,
          0.5469979379158498,
          0.47831484649655953,
          0.4703498415307039,
          0.4852333427712291,
          0.49910301316456873,
          0.5030643576619461,
          0.5419288275646672,
          0.49197797863528314,
          0.4978981680623321,
          0.4913172018193961,
          0.5242411735452495,
          0.5099703351707487,
          0.5400236333796856,
          0.4623685138934117,
          0.4905540085881235,
          0.508460701022631,
          0.5170974578859824,
          0.5634106296877089,
          0.4805015507990833,
          0.6002546395916368,
          0.44970631176434184,
          0.5435148130759921,
          0.4701802253130606,
          0.5038295673286711,
          0.4802263765404011,
          0.4824802545267396,
          0.5248872022900714,
          0.6023877058867896,
          0.49931709233941124,
          0.5805446791733786,
          0.5445493799124156,
          0.44801486181997296,
          0.4817279166505234,
          0.47191129602907245,
          0.5371559096297462,
          0.5005898795966877,
          0.5086060693446763,
          0.5498993575608961,
          0.49527576444899557,
          0.5544104042073204,
          0.5597725250741715,
          0.5680713076135708,
          0.48184217463525314,
          0.5013552333335001,
          0.5582478505217572,
          0.5042628465234178,
          0.5013251517768018,
          0.4862473477647177,
          0.4937825190673275,
          0.4795844912357593,
          0.5049972757325565,
          0.47674074060147187,
          0.48614972926854116,
          0.49558910330336914,
          0.5243183186310786,
          0.45214727906801533,
          0.49262284920506494,
          0.5140280844135621,
          0.5251343251338704,
          0.4881231757410609,
          0.5270095031042046,
          0.5230169928949437,
          0.5368825411868616,
          0.5657298907494255,
          0.5901358058763444,
          0.42664785522824167,
          0.568665414046073,
          0.49422866223580264,
          0.5442717413194126,
          0.5673140160661094,
          0.5594647265811514,
          0.5277472933779104,
          0.47810808331414856,
          0.5403989226800496,
          0.4920681893431219,
          0.4416095677411622,
          0.6450873452902692,
          0.5597976770342163,
          0.4921762012822991,
          0.5087287555486055,
          0.5265315138192219,
          0.5362687043940051,
          0.4963114270307818,
          0.5326020261832809,
          0.5325745467535352,
          0.480262644364127,
          0.496312080770145,
          0.4599908830710947,
          0.45954021578349646,
          0.5825910010403574,
          0.508171581042147,
          0.4752728468415468,
          0.5161950955229314,
          0.5675030083338943,
          0.5305567564525775,
          0.4903286718567189,
          0.544502166100309
         ],
         "xaxis": "x",
         "y": [
          0.004199964639353156,
          0.03507850778060369,
          0.005012576731270404,
          0.016266507479423056,
          0.12452126511982803,
          0.002183210631074768,
          0.09312875203939656,
          0.008310964560175316,
          0.00013670861564284007,
          0.0056349600814756965,
          0.00549664562684498,
          0.0002425119375123242,
          0.03755671546371923,
          0.019165289316185382,
          0.001738653673008434,
          0.003247942624854809,
          0.00444310358290059,
          0.00008842398514206764,
          0.015212385025439026,
          0.00003140653782092283,
          0.020752424707072413,
          0.00507923861089162,
          0.0029332351917027545,
          0.007205345351924314,
          0.005171887580209425,
          0.007462247955358621,
          0.0037572689740302326,
          0.0036493087560592057,
          0.012187036962287278,
          0.0021190909468524668,
          0.000005104258123914279,
          0.01464828435369838,
          0.002626362727391058,
          0.003283038595499895,
          0.0000610590612847817,
          0.022236924943930265,
          0.001585119808690479,
          0.021916500498507328,
          0.0019064684320867042,
          0.00020684009751337727,
          0.002362538852179608,
          0.009927776179364205,
          0.01638748914210929,
          0.00012328891635579695,
          0.006997038075626794,
          0.008945285401707965,
          0.00001601190526512859,
          0.02576046165773254,
          0.019667791192480855,
          0.002510505796117169,
          0.002956377268069536,
          0.05153416449460707,
          0.011639734405961456,
          0.009470459547135504,
          0.00026735782768148473,
          0.007308485883588867,
          0.02860952761459092,
          0.022968981313817825,
          0.012846420595959397,
          0.0006495889185062978,
          0.009326577776635661,
          0.006555792944334467,
          0.004588968310047788,
          0.000007639783509856334,
          0.00009644778163890152,
          0.003814474381363621,
          0.0166402259025422,
          0.005461035569017383,
          0.09073075312095309,
          0.015174024308986013,
          0.0035643732992788947,
          0.00044417153399674633,
          0.07623806361678323,
          0.00005166530590824989,
          0.006539850385320606,
          0.00016263762931382274,
          0.09835948144945245,
          0.0027103793268004463,
          0.0003187325530286137,
          0.0008298718381505878,
          0.019011673174211,
          0.0013868035607266672,
          0.0014516705297284648,
          0.002273087910108834,
          0.011783979380960763,
          0.0020714423899309553,
          0.001666938569924887,
          0.0037518094761881254,
          0.01806661405141188,
          0.0025283023676371348,
          0.013699237374471183,
          0.0007460880618914116,
          0.003247487050188023,
          0.0007459123805642074,
          0.001924876904059073,
          0.025185698540451978,
          0.00023251638695821845,
          0.000024805457058130896,
          0.002694713664648162,
          0.00009373779967164429
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "tracegroupgap": 0
        },
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "In-Sample vs. Out-of-Sample R-squared for Model4"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "In-Sample R-squared"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Out-Sample R-squared"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define Model5 parameters\n",
    "model_name = \"Model4\"\n",
    "data = pokeaman  # The full dataset\n",
    "\n",
    "# Number of repetitions\n",
    "num_repetitions = 100\n",
    "\n",
    "# Initialize list to store performance metrics\n",
    "performance_metrics = []\n",
    "\n",
    "# Repeat the process for Model5\n",
    "for _ in range(num_repetitions):\n",
    "    # Randomly split the data into 50% train and 50% test\n",
    "    train_data, test_data = train_test_split(data, train_size=0.5)\n",
    "\n",
    "    # Fit the model on the training data\n",
    "    model_spec = smf.ols(formula=model4_linear_form, data=train_data)\n",
    "    model_fit = model_spec.fit()\n",
    "\n",
    "    # Calculate in-sample R-squared\n",
    "    in_sample_r2 = model_fit.rsquared\n",
    "\n",
    "    # Predict on test data\n",
    "    y_test = test_data.HP\n",
    "    yhat_test = model_fit.predict(test_data)\n",
    "\n",
    "    # Calculate out-of-sample R-squared\n",
    "    if len(y_test) > 1:  # Ensure there is enough data for correlation calculation\n",
    "        out_sample_r2 = np.corrcoef(y_test, yhat_test)[0, 1] ** 2\n",
    "    else:\n",
    "        out_sample_r2 = np.nan  # Handle cases with insufficient test data\n",
    "\n",
    "    # Store the results\n",
    "    performance_metrics.append({\n",
    "        \"Repetition\": _ + 1,\n",
    "        \"In-Sample R2\": in_sample_r2,\n",
    "        \"Out-Sample R2\": out_sample_r2,\n",
    "    })\n",
    "\n",
    "# Convert metrics to a DataFrame\n",
    "performance_df = pd.DataFrame(performance_metrics)\n",
    "\n",
    "# Plot the scatter plot using Plotly\n",
    "fig = px.scatter(\n",
    "    performance_df,\n",
    "    x=\"In-Sample R2\",\n",
    "    y=\"Out-Sample R2\",\n",
    "    title=f\"In-Sample vs Out-of-Sample R-squared ({model_name})\",\n",
    "    labels={\"In-Sample R2\": \"In-Sample R-squared\", \"Out-Sample R2\": \"Out-of-Sample R-squared\"},\n",
    "    text=\"Repetition\",\n",
    "    hover_data=[\"Repetition\"]\n",
    ")\n",
    "\n",
    "# Customize layout\n",
    "fig.update_traces(marker=dict(size=8))\n",
    "fig.update_layout(\n",
    "    title=f\"In-Sample vs. Out-of-Sample R-squared for {model_name}\",\n",
    "    xaxis=dict(title=\"In-Sample R-squared\"),\n",
    "    yaxis=dict(title=\"Out-Sample R-squared\"),\n",
    "    showlegend=False\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model had terrible generalizability due to it's over complexity. We see that the range for the in-sample r-squared maintains around 0.40 to 0.6, which isn't a big range. And all of the out-sample r-squared values barely surpass 0.1. This is an example of severe overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "customdata": [
          [
           1
          ],
          [
           2
          ],
          [
           3
          ],
          [
           4
          ],
          [
           5
          ],
          [
           6
          ],
          [
           7
          ],
          [
           8
          ],
          [
           9
          ],
          [
           10
          ],
          [
           11
          ],
          [
           12
          ],
          [
           13
          ],
          [
           14
          ],
          [
           15
          ],
          [
           16
          ],
          [
           17
          ],
          [
           18
          ],
          [
           19
          ],
          [
           20
          ],
          [
           21
          ],
          [
           22
          ],
          [
           23
          ],
          [
           24
          ],
          [
           25
          ],
          [
           26
          ],
          [
           27
          ],
          [
           28
          ],
          [
           29
          ],
          [
           30
          ],
          [
           31
          ],
          [
           32
          ],
          [
           33
          ],
          [
           34
          ],
          [
           35
          ],
          [
           36
          ],
          [
           37
          ],
          [
           38
          ],
          [
           39
          ],
          [
           40
          ],
          [
           41
          ],
          [
           42
          ],
          [
           43
          ],
          [
           44
          ],
          [
           45
          ],
          [
           46
          ],
          [
           47
          ],
          [
           48
          ],
          [
           49
          ],
          [
           50
          ],
          [
           51
          ],
          [
           52
          ],
          [
           53
          ],
          [
           54
          ],
          [
           55
          ],
          [
           56
          ],
          [
           57
          ],
          [
           58
          ],
          [
           59
          ],
          [
           60
          ],
          [
           61
          ],
          [
           62
          ],
          [
           63
          ],
          [
           64
          ],
          [
           65
          ],
          [
           66
          ],
          [
           67
          ],
          [
           68
          ],
          [
           69
          ],
          [
           70
          ],
          [
           71
          ],
          [
           72
          ],
          [
           73
          ],
          [
           74
          ],
          [
           75
          ],
          [
           76
          ],
          [
           77
          ],
          [
           78
          ],
          [
           79
          ],
          [
           80
          ],
          [
           81
          ],
          [
           82
          ],
          [
           83
          ],
          [
           84
          ],
          [
           85
          ],
          [
           86
          ],
          [
           87
          ],
          [
           88
          ],
          [
           89
          ],
          [
           90
          ],
          [
           91
          ],
          [
           92
          ],
          [
           93
          ],
          [
           94
          ],
          [
           95
          ],
          [
           96
          ],
          [
           97
          ],
          [
           98
          ],
          [
           99
          ],
          [
           100
          ]
         ],
         "hovertemplate": "In-Sample R-squared=%{x}<br>Out-of-Sample R-squared=%{y}<br>Repetition=%{customdata[0]}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": "#636efa",
          "size": 8,
          "symbol": "circle"
         },
         "mode": "markers+text",
         "name": "",
         "orientation": "v",
         "showlegend": false,
         "text": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100
         ],
         "type": "scatter",
         "x": [
          0.39350574022625995,
          0.38012367478128684,
          0.41347908929521093,
          0.36135203875730415,
          0.4729483212772143,
          0.45298892831485205,
          0.46023023837006116,
          0.37226294219859524,
          0.3317981347586736,
          0.4094693119219235,
          0.3887087625384097,
          0.38485461446542146,
          0.4135545792913794,
          0.44091389295765604,
          0.40402651305758763,
          0.48277801500365736,
          0.40946535971669495,
          0.35529049991388306,
          0.3624535027427759,
          0.35910789883279537,
          0.40354866950354285,
          0.32813017522170596,
          0.3861898941299693,
          0.37594777097914134,
          0.43688296328267073,
          0.4114096579178558,
          0.43998373012556036,
          0.44687022433615775,
          0.41526097857393107,
          0.4095856421947063,
          0.41665392118002575,
          0.3822012946957627,
          0.4001195185326629,
          0.4006768085446164,
          0.4370608526298221,
          0.42594725290555735,
          0.49305573742593134,
          0.3428801196229919,
          0.4079400786182641,
          0.39596125219377376,
          0.38403970045991864,
          0.41783570714105445,
          0.3853708523335231,
          0.39158744026798575,
          0.42517249583586825,
          0.4417426787386102,
          0.3775869295738472,
          0.3219338754681229,
          0.3289417677457678,
          0.38696979271689946,
          0.3634371461394308,
          0.43972549680831996,
          0.4343220900962719,
          0.4493479319920336,
          0.3608535164929372,
          0.4238792667179764,
          0.40150953533744393,
          0.36448565901246943,
          0.3960998590821867,
          0.3751033811390141,
          0.4587458512434225,
          0.4286078598852684,
          0.4621482031558415,
          0.4270547255040682,
          0.4569477838680329,
          0.45919956010577834,
          0.42171546251827086,
          0.4059020177846845,
          0.43197214978723886,
          0.39723598123679826,
          0.36816253064225035,
          0.4029657903455841,
          0.3735684813286365,
          0.42762740454377823,
          0.4892606434478898,
          0.4697423180314336,
          0.40065616996374054,
          0.3278841329908919,
          0.5101988783231379,
          0.3866898864413034,
          0.42287012692579573,
          0.40664092764868365,
          0.36871132866592227,
          0.41664006260458475,
          0.3548584559859329,
          0.4002068735508688,
          0.3493727366310595,
          0.38601643841499045,
          0.38514731833664884,
          0.392321875899307,
          0.38537230505120246,
          0.40130676579782887,
          0.3572745784465108,
          0.3708725950421635,
          0.5197007552639609,
          0.34914989208717984,
          0.45261714646254114,
          0.3782522165478256,
          0.3681430070906673,
          0.3918912730675569
         ],
         "xaxis": "x",
         "y": [
          0.2745504442861736,
          0.2597314352538261,
          0.2541752430450113,
          0.3495776911915093,
          0.22625146595560017,
          0.28014017363135535,
          0.25392373378206307,
          0.19528102487500934,
          0.38570121493824533,
          0.3173081542025332,
          0.28374142980796146,
          0.26117275416768504,
          0.28641184460848795,
          0.24177669047073733,
          0.2952807375844777,
          0.2341582023752225,
          0.3007829062022429,
          0.3759648056248799,
          0.373728687337348,
          0.34585439598597184,
          0.31940621255721374,
          0.350094683294482,
          0.3269081373609255,
          0.3024580105391711,
          0.28248511334044873,
          0.2604988145367232,
          0.28893498742631807,
          0.2382187609739212,
          0.2915389515034938,
          0.20654894431303317,
          0.31697004129981027,
          0.24921416397497118,
          0.3212852203188109,
          0.3239960238063487,
          0.2673730106149411,
          0.28774615166163653,
          0.28370316644163207,
          0.3585262504176376,
          0.26642316086342244,
          0.31146718795208356,
          0.28947357338276225,
          0.30182113831511287,
          0.28000832504107115,
          0.23425323289733088,
          0.21726684385806938,
          0.24393843215661834,
          0.3140478185216748,
          0.3739438693390835,
          0.39918054179483015,
          0.22688581264000737,
          0.30283129245714774,
          0.2796995820196589,
          0.20762593582827774,
          0.2893852226529982,
          0.35425041835139176,
          0.2788041581754822,
          0.3161396378939183,
          0.2749868778729416,
          0.3148720130423023,
          0.24742090930359908,
          0.23000862379543424,
          0.27200238552970857,
          0.24285424837522573,
          0.27848178116850364,
          0.2948765697622163,
          0.23835881480613805,
          0.3186846389002592,
          0.3147604557231397,
          0.21301953414444333,
          0.3283152853078836,
          0.3449905787181018,
          0.315438097293573,
          0.27263523178395427,
          0.3052035407170384,
          0.24092578756043204,
          0.22835657986247287,
          0.312602555476695,
          0.3946858509773138,
          0.26155778257601076,
          0.31080480859982235,
          0.2703720205100633,
          0.31642164335979805,
          0.33593780825021696,
          0.19484406355506004,
          0.35358586992670266,
          0.2723521758776706,
          0.35716657594129264,
          0.30125708738538504,
          0.3373615264499625,
          0.3011539219921202,
          0.3236251170600246,
          0.29407518932325966,
          0.25767209145349057,
          0.28954094835795546,
          0.23851094162344014,
          0.3210986384645871,
          0.2595965866359334,
          0.3369958535219082,
          0.33358842765633323,
          0.3180986343252244
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "tracegroupgap": 0
        },
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "In-Sample vs. Out-of-Sample R-squared for Model7"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "In-Sample R-squared"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Out-Sample R-squared"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define Model5 parameters\n",
    "model_name = \"Model7\"\n",
    "data = pokeaman  # The full dataset\n",
    "\n",
    "# Number of repetitions\n",
    "num_repetitions = 100\n",
    "\n",
    "# Initialize list to store performance metrics\n",
    "performance_metrics = []\n",
    "\n",
    "# Repeat the process for Model5\n",
    "for _ in range(num_repetitions):\n",
    "    # Randomly split the data into 50% train and 50% test\n",
    "    train_data, test_data = train_test_split(data, train_size=0.5)\n",
    "\n",
    "    # Fit the model on the training data\n",
    "    model_spec = smf.ols(formula=model7_linear_form, data=train_data)\n",
    "    model_fit = model_spec.fit()\n",
    "\n",
    "    # Calculate in-sample R-squared\n",
    "    in_sample_r2 = model_fit.rsquared\n",
    "\n",
    "    # Predict on test data\n",
    "    y_test = test_data.HP\n",
    "    yhat_test = model_fit.predict(test_data)\n",
    "\n",
    "    # Calculate out-of-sample R-squared\n",
    "    if len(y_test) > 1:  # Ensure there is enough data for correlation calculation\n",
    "        out_sample_r2 = np.corrcoef(y_test, yhat_test)[0, 1] ** 2\n",
    "    else:\n",
    "        out_sample_r2 = np.nan  # Handle cases with insufficient test data\n",
    "\n",
    "    # Store the results\n",
    "    performance_metrics.append({\n",
    "        \"Repetition\": _ + 1,\n",
    "        \"In-Sample R2\": in_sample_r2,\n",
    "        \"Out-Sample R2\": out_sample_r2,\n",
    "    })\n",
    "\n",
    "# Convert metrics to a DataFrame\n",
    "performance_df = pd.DataFrame(performance_metrics)\n",
    "\n",
    "# Plot the scatter plot using Plotly\n",
    "fig = px.scatter(\n",
    "    performance_df,\n",
    "    x=\"In-Sample R2\",\n",
    "    y=\"Out-Sample R2\",\n",
    "    title=f\"In-Sample vs Out-of-Sample R-squared ({model_name})\",\n",
    "    labels={\"In-Sample R2\": \"In-Sample R-squared\", \"Out-Sample R2\": \"Out-of-Sample R-squared\"},\n",
    "    text=\"Repetition\",\n",
    "    hover_data=[\"Repetition\"]\n",
    ")\n",
    "\n",
    "# Customize layout\n",
    "fig.update_traces(marker=dict(size=8))\n",
    "fig.update_layout(\n",
    "    title=f\"In-Sample vs. Out-of-Sample R-squared for {model_name}\",\n",
    "    xaxis=dict(title=\"In-Sample R-squared\"),\n",
    "    yaxis=dict(title=\"Out-Sample R-squared\"),\n",
    "    showlegend=False\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not as clear as `model6`, but we also do kinda see the negative relationship trend between in-sample and out-sample r-squareds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I don't know why I can't run model5...\n",
    "\n",
    "But anyways, overall, if we look at the graphs for `model6` and `model7`, we do see something very interesting. Both models show a somewhat strong negative relationship between the In-sample and out-of-sample r-squared values. **What this is implying is that the higher the in-sample r-squared value is, (which refers to how well the model is fitting on the training data), the lower the out-of-sample r-squared values**. This directly relates back to the concept of **overfitting** like we've discussed before, when we see the big drop when comparing the in-sample and out-of-sample r-squared values, it likely points towards evidence that the model is too complex relative to the data used to train it, causing it to have poor generalizability, so, when it meets test data it hasn't seen before, it fails to predict the outcome accuately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 9\n",
    "\n",
    "The four blocks of code in this section further explore the models `model6` and `model7` by looking at the generalizability acorss generations of Pokemon to see how well data from earlier generations \"translate\" to later generations, or whether or not models trained on data from these earlier generations will be able to generalize future generations. It also explores the impact of model complexity (`model6` vs `model7`) in terms of generalizability between Pokemon generations.\n",
    "\n",
    "In the four blocks of code, the first two are using the formula used in the previous `model7` specifications, and the last two are using the formula used in the `model6` specification. Then, the first and third blocks of code fitted the model on data from 1st Generation Pokemon, and tested them on all other generations, and the second and fourth blocks of code fitted the model on data from the 1st to 5th generation Pokemon, and tested them on 6th generation Pokemon.\n",
    "\n",
    "One of the main takeaways from these four experiments are illustrating the importance of training on diverse data, we can see from both pairs of experiments from `model6` and `model7` that, the generalizability of the models trained on generations 1 to 5 and tested on generation 6 do significantly better than the models fitted on generation 1 and tested on other generations.\n",
    "\n",
    "It also illustrates the importance of choosing the right level of model complexity, as overly complex models, like we've previously seen from Question 5, may overfit the training data and fail to generalize. We can also see this from the two experiments with `model6` and `model7` fitted on 1st generation data. We see that, the more complicated `model7` has a higher in-sample r-squared, compared to the simpler `model6`, but has a lower out-of-sample r-squared. In fact, the difference between the in-sample and out-of-sample r-squared for `model7` is greater compared to that of `model6`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
